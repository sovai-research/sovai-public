{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sovai[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1bbb4-8c20-43e6-bfc5-012f4361bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consumer Financial Complaints is very mislabelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaade139-f0f4-41c3-b277-a71b24f8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up Notion credentials (hardcoded as per your request)\n",
    "NOTION_TOKEN = \"your_notion_token_here\"  # **Ensure this token is kept secure!**\n",
    "DATABASE_ID = \"your_database_id_here\"\n",
    "NOTION_VERSION = \"2022-06-28\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": NOTION_VERSION,\n",
    "}\n",
    "\n",
    "def create_page(title, database_id, children):\n",
    "    \"\"\"\n",
    "    Creates a new page in the specified Notion database.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        children (list): A list of block objects to include in the page.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    page_data = {\n",
    "        \"parent\": {\"database_id\": database_id},\n",
    "        \"properties\": {\n",
    "            \"Title\": {\n",
    "                \"title\": [\n",
    "                    {\n",
    "                        \"text\": {\n",
    "                            \"content\": title\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        \"children\": children\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.notion.com/v1/pages\", headers=headers, json=page_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def find_page_by_title(database_id, title):\n",
    "    \"\"\"\n",
    "    Searches the Notion database for a page with the specified title.\n",
    "\n",
    "    Args:\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        title (str): The title to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The page object if found, else None.\n",
    "    \"\"\"\n",
    "    query_url = f\"https://api.notion.com/v1/databases/{database_id}/query\"\n",
    "    query_data = {\n",
    "        \"filter\": {\n",
    "            \"property\": \"Title\",\n",
    "            \"title\": {\n",
    "                \"equals\": title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(query_url, headers=headers, json=query_data)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to query database:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        return None\n",
    "\n",
    "    results = response.json().get(\"results\")\n",
    "    if results:\n",
    "        return results[0]  # Assuming titles are unique\n",
    "    return None\n",
    "\n",
    "\n",
    "def append_to_page(page_id, children):\n",
    "    \"\"\"\n",
    "    Appends new blocks to an existing Notion page.\n",
    "\n",
    "    Args:\n",
    "        page_id (str): The ID of the page to append to.\n",
    "        children (list): A list of block objects to append.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    append_url = f\"https://api.notion.com/v1/blocks/{page_id}/children\"\n",
    "    append_data = {\n",
    "        \"children\": children\n",
    "    }\n",
    "    response = requests.patch(append_url, headers=headers, json=append_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def build_content_from_dict(content_dict):\n",
    "    \"\"\"\n",
    "    Builds Notion content blocks from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing content definitions.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Add Heading\n",
    "    if \"heading\" in content_dict and content_dict[\"heading\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"heading_2\",\n",
    "                \"heading_2\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"heading\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Add Content\n",
    "    if \"content\" in content_dict and content_dict[\"content\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"content\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add List Items (Bullet Points)\n",
    "    if \"list\" in content_dict and content_dict[\"list\"]:\n",
    "        list_blocks = build_bullet_list(content_dict[\"list\"])\n",
    "        children.extend(list_blocks)\n",
    "        \n",
    "    # Add URL as a Link\n",
    "    if \"url\" in content_dict and content_dict[\"url\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"url\"],\n",
    "                                \"link\": {\"url\": content_dict[\"url\"]}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "def build_bullet_list(items):\n",
    "    \"\"\"\n",
    "    Builds Notion bullet list blocks from a list of items.\n",
    "\n",
    "    Args:\n",
    "        items (list): A list of strings representing bullet points.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion bulleted list item block objects.\n",
    "    \"\"\"\n",
    "    bullet_blocks = []\n",
    "    for item in items:\n",
    "        bullet_blocks.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"bulleted_list_item\",\n",
    "                \"bulleted_list_item\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": item\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    return bullet_blocks\n",
    "\n",
    "\n",
    "def build_children_from_sections(content_sections):\n",
    "    \"\"\"\n",
    "    Iterates through the content sections dictionary and builds the children blocks.\n",
    "\n",
    "    Args:\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "    for key in sorted(content_sections.keys()):\n",
    "        section = content_sections[key]\n",
    "        section_blocks = build_content_from_dict(section)\n",
    "        children.extend(section_blocks)\n",
    "    return children\n",
    "\n",
    "\n",
    "def handle_page_creation_or_append(title, database_id, content_sections):\n",
    "    \"\"\"\n",
    "    Handles the logic to either create a new page or append content to an existing page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    full_title = f\"{title} - {current_date}\"\n",
    "\n",
    "    # Build the content blocks\n",
    "    children = build_children_from_sections(content_sections)\n",
    "\n",
    "    # Check if the page already exists\n",
    "    existing_page = find_page_by_title(database_id, full_title)\n",
    "\n",
    "    if existing_page:\n",
    "        print(f\"Page '{full_title}' already exists. Appending new content to it.\")\n",
    "        page_id = existing_page[\"id\"]\n",
    "        response = append_to_page(page_id, children)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"New content appended successfully.\")\n",
    "            # Construct the page URL manually\n",
    "            # Note: Notion page URLs follow the format https://www.notion.so/{workspace}/{page_id}\n",
    "            # However, constructing the exact URL might require additional steps.\n",
    "            # Here, we'll provide a placeholder.\n",
    "            page_url = f\"https://www.notion.so/{page_id.replace('-', '')}\"\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to append new content:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f\"Page '{full_title}' does not exist. Creating a new page with the new content.\")\n",
    "        response = create_page(full_title, database_id, children)\n",
    "        \n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            page_url = response.json().get(\"url\", \"No URL returned\")\n",
    "            print(\"Page created successfully with the new content.\")\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to create page:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15dafb6d-a016-43d3-8406-f91f727f7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/complaints/public\n",
      "Requesting URL: https://data.sov.ai/complaints/public with params: {'parquet': 'True', 'full_history': 'True'}\n",
      "Returning cached data\n",
      "Missing Values in Each Column:\n",
      " ticker                  0\n",
      "month_end               0\n",
      "company              1491\n",
      "complaint_count         0\n",
      "culpability_score    1491\n",
      "complaint_score      1491\n",
      "grievance_score      1491\n",
      "total_risk_rating    1491\n",
      "similarity           1491\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Authenticate with Sovai\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\") \n",
    "\n",
    "# Load data\n",
    "df_complaints = sov.data(\"complaints/public\", verbose=True, full_history=True)\n",
    "\n",
    "# Data Preprocessing\n",
    "df_complaints['date'] = pd.to_datetime(df_complaints['date'])\n",
    "today = pd.Timestamp.now()\n",
    "thirteen_months_ago = today - pd.DateOffset(months=14)\n",
    "df_complaints = df_complaints[df_complaints['date'] >= thirteen_months_ago]\n",
    "max_date = df_complaints['date'].max()\n",
    "\n",
    "def get_monthly_end_date(dt):\n",
    "    return dt.replace(day=max_date.day) if dt.day <= max_date.day else (\n",
    "        dt + pd.offsets.MonthEnd(0) - pd.Timedelta(days=max_date.day-1)\n",
    "    )\n",
    "\n",
    "df_complaints['month_end'] = df_complaints['date'].apply(get_monthly_end_date)\n",
    "df_complaints.set_index('month_end', inplace=True)\n",
    "\n",
    "df_monthly = df_complaints.groupby('ticker').resample('M', label='right', closed='right').agg({\n",
    "    'company': 'first',\n",
    "    'ticker': 'count',\n",
    "    'culpability_score': 'mean',\n",
    "    'complaint_score': 'mean',\n",
    "    'grievance_score': 'mean',\n",
    "    'total_risk_rating': 'mean',\n",
    "    'similarity': 'mean'\n",
    "})\n",
    "\n",
    "df_monthly.rename(columns={'ticker': 'complaint_count'}, inplace=True)\n",
    "df_monthly.reset_index(inplace=True)\n",
    "df_monthly.sort_values(['month_end', 'ticker'], ascending=[False, True], inplace=True)\n",
    "\n",
    "df_monthly['month_end'] = df_monthly['month_end'].apply(\n",
    "    lambda x: x.replace(day=max_date.day) if x.month != max_date.month or x.year != max_date.year\n",
    "    else max_date\n",
    ")\n",
    "\n",
    "# Handle missing values\n",
    "missing_values = df_monthly.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
    "\n",
    "numerical_cols = ['complaint_count', 'culpability_score', 'complaint_score',\n",
    "                  'grievance_score', 'total_risk_rating', 'similarity']\n",
    "df_monthly[numerical_cols] = df_monthly[numerical_cols].fillna(df_monthly[numerical_cols].median())\n",
    "\n",
    "df_monthly['ticker'] = df_monthly['ticker'].fillna('UNKNOWN')\n",
    "df_monthly['company'] = df_monthly['company'].fillna('UNKNOWN')\n",
    "\n",
    "# Define the Anomaly Detection Function\n",
    "def detect_anomalies(df, metrics, historical_months=12, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Detect anomalies in the latest month's data based on historical data.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The monthly aggregated data DataFrame.\n",
    "    - metrics (list): List of metric column names to use for anomaly detection.\n",
    "    - historical_months (int): Number of months to consider as historical data.\n",
    "    - contamination (float): The proportion of anomalies in the data set for Isolation Forest.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with anomaly scores and labels.\n",
    "    \"\"\"\n",
    "    # Ensure 'month_end' is in datetime format\n",
    "    df['month_end'] = pd.to_datetime(df['month_end'])\n",
    "\n",
    "    # Sort data by 'month_end' to ensure chronological order\n",
    "    df = df.sort_values('month_end')\n",
    "\n",
    "    # Identify the latest month in the data\n",
    "    latest_month = df['month_end'].max()\n",
    "\n",
    "    # Define the historical period\n",
    "    historical_start_date = latest_month - pd.DateOffset(months=historical_months)\n",
    "\n",
    "    # Extract historical data (12 months before the latest month)\n",
    "    historical_data = df[(df['month_end'] >= historical_start_date) & \n",
    "                         (df['month_end'] < latest_month)]\n",
    "\n",
    "    # Extract current month data\n",
    "    current_month_data = df[df['month_end'] == latest_month]\n",
    "\n",
    "    # Check if historical_data is empty\n",
    "    if historical_data.empty:\n",
    "        raise ValueError(\"Historical data is empty. Adjust the historical_months parameter or check the data.\")\n",
    "\n",
    "    # a. Calculate historical statistics (mean and std) for each metric per ticker\n",
    "    stats = historical_data.groupby('ticker')[metrics].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    stats.columns = ['ticker'] + [f\"{metric}_{stat}\" for metric in metrics for stat in ['mean', 'std']]\n",
    "\n",
    "    # b. Merge historical statistics with current month data\n",
    "    merged_data = current_month_data.merge(stats, on='ticker', how='left')\n",
    "\n",
    "    # c. Handle missing statistics\n",
    "    for metric in metrics:\n",
    "        mean_col = f\"{metric}_mean\"\n",
    "        std_col = f\"{metric}_std\"\n",
    "        merged_data[mean_col] = merged_data[mean_col].fillna(merged_data[metric])\n",
    "        merged_data[std_col] = merged_data[std_col].fillna(0)\n",
    "\n",
    "    # d. Calculate Z-Scores for each metric\n",
    "    for metric in metrics:\n",
    "        z_col = f\"{metric}_z\"\n",
    "        mean_col = f\"{metric}_mean\"\n",
    "        std_col = f\"{metric}_std\"\n",
    "        # Avoid division by zero by replacing 0 std with a small number\n",
    "        merged_data[z_col] = (merged_data[metric] - merged_data[mean_col]) / merged_data[std_col].replace(0, 1e-6)\n",
    "        merged_data[z_col] = merged_data[z_col].fillna(0)\n",
    "\n",
    "    # e. Combine Z-Scores into a Signed Composite Anomaly Score\n",
    "    # Instead of using Euclidean distance, sum the z-scores to preserve the direction\n",
    "    merged_data['anomaly_score'] = merged_data[[f\"{metric}_z\" for metric in metrics]].sum(axis=1)\n",
    "    \n",
    "    # Alternatively, you can use the mean if you prefer normalization\n",
    "    # merged_data['anomaly_score'] = merged_data[[f\"{metric}_z\" for metric in metrics]].mean(axis=1)\n",
    "\n",
    "    # f. Isolation Forest for advanced anomaly detection (Optional)\n",
    "    feature_cols = [f\"{metric}_z\" for metric in metrics]\n",
    "    X = merged_data[feature_cols].fillna(0)\n",
    "\n",
    "    # Initialize Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "\n",
    "    # Fit the model and predict anomalies\n",
    "    iso_forest.fit(X)\n",
    "    merged_data['anomaly_label_iso'] = iso_forest.predict(X)\n",
    "\n",
    "    # Anomaly labels: -1 for anomalies, 1 for normal\n",
    "    merged_data['is_anomaly_iso'] = merged_data['anomaly_label_iso'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "# Define Metrics and Detect Anomalies\n",
    "metrics = [\n",
    "    'complaint_count', \n",
    "    'culpability_score', \n",
    "    'complaint_score', \n",
    "    'grievance_score', \n",
    "    'total_risk_rating', \n",
    "    # 'similarity'\n",
    "]\n",
    "\n",
    "# Call the anomaly detection function\n",
    "try:\n",
    "    analyzed_data = detect_anomalies(df_monthly, metrics)\n",
    "except ValueError as ve:\n",
    "    print(f\"Error: {ve}\")\n",
    "    analyzed_data = pd.DataFrame()  # Create an empty DataFrame in case of error\n",
    "\n",
    "# Representation and Visualization\n",
    "final_representation = analyzed_data[[\n",
    "    'month_end', 'ticker', 'company', 'complaint_count', 'culpability_score',\n",
    "    'complaint_score', 'grievance_score', 'total_risk_rating',\n",
    "    'similarity', 'anomaly_score', 'is_anomaly_iso'\n",
    "]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca75a559-6747-4b1a-ad50-6ac6b965be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_end</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>culpability_score</th>\n",
       "      <th>complaint_score</th>\n",
       "      <th>grievance_score</th>\n",
       "      <th>total_risk_rating</th>\n",
       "      <th>similarity</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly_iso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>EFSI</td>\n",
       "      <td>eagle financial services, inc.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>EFX</td>\n",
       "      <td>equifax, inc.</td>\n",
       "      <td>53444</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-8.450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>ELVT</td>\n",
       "      <td>elevate recoveries, llc</td>\n",
       "      <td>4</td>\n",
       "      <td>0.822</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.920</td>\n",
       "      <td>-2.047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>EML</td>\n",
       "      <td>eastern revenue, inc.</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.922</td>\n",
       "      <td>-2.742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>ENTOF</td>\n",
       "      <td>entrata inc.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.942</td>\n",
       "      <td>-2.570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>OUSZF</td>\n",
       "      <td>the outsource group, inc</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-1.265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>PABN</td>\n",
       "      <td>panamerican consulting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-21.191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>PAY</td>\n",
       "      <td>payfare international inc.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.987</td>\n",
       "      <td>-3.796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>OPOSF</td>\n",
       "      <td>optio solutions, llc</td>\n",
       "      <td>7</td>\n",
       "      <td>0.778</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-1.447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>1725688D</td>\n",
       "      <td>american management services, inc.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_end    ticker                             company  complaint_count  \\\n",
       "0   2024-10-27      EFSI      eagle financial services, inc.                1   \n",
       "1   2024-10-27       EFX                       equifax, inc.            53444   \n",
       "2   2024-10-27      ELVT             elevate recoveries, llc                4   \n",
       "3   2024-10-27       EML               eastern revenue, inc.                4   \n",
       "4   2024-10-27     ENTOF                        entrata inc.                1   \n",
       "..         ...       ...                                 ...              ...   \n",
       "274 2024-10-27     OUSZF            the outsource group, inc                2   \n",
       "275 2024-10-27      PABN              panamerican consulting                1   \n",
       "276 2024-10-27       PAY          payfare international inc.                1   \n",
       "277 2024-10-27     OPOSF                optio solutions, llc                7   \n",
       "278 2024-10-27  1725688D  american management services, inc.                2   \n",
       "\n",
       "     culpability_score  complaint_score  grievance_score  total_risk_rating  \\\n",
       "0                0.768           -0.167            0.218              0.273   \n",
       "1                0.233           -0.256            0.009             -0.005   \n",
       "2                0.822           -0.255            0.243              0.270   \n",
       "3                0.810           -0.214            0.020              0.206   \n",
       "4                0.769           -0.256            0.151              0.221   \n",
       "..                 ...              ...              ...                ...   \n",
       "274              0.821           -0.237            0.514              0.366   \n",
       "275              0.988           -0.432            0.040              0.198   \n",
       "276              0.619           -0.269           -0.481             -0.043   \n",
       "277              0.778           -0.209            0.263              0.277   \n",
       "278              0.910            0.053            0.150              0.371   \n",
       "\n",
       "     similarity  anomaly_score  is_anomaly_iso  \n",
       "0         1.000         -2.079               0  \n",
       "1         1.000         -8.450               0  \n",
       "2         0.920         -2.047               0  \n",
       "3         0.922         -2.742               0  \n",
       "4         0.942         -2.570               0  \n",
       "..          ...            ...             ...  \n",
       "274       0.982         -1.265               0  \n",
       "275       0.978        -21.191               1  \n",
       "276       0.987         -3.796               0  \n",
       "277       0.910         -1.447               0  \n",
       "278       0.885          0.352               0  \n",
       "\n",
       "[279 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1481a1-7492-4caf-b387-a5e2d502ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_representation = final_representation[final_representation[\"complaint_count\"]>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd28a6c-0767-413c-afbd-611ecc962ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_representation = final_representation.drop(columns=[\"is_anomaly_iso\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42a7eed8-aa46-482f-a79e-46ae0f1f0719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_end</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>complaint_count</th>\n",
       "      <th>culpability_score</th>\n",
       "      <th>complaint_score</th>\n",
       "      <th>grievance_score</th>\n",
       "      <th>total_risk_rating</th>\n",
       "      <th>similarity</th>\n",
       "      <th>anomaly_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>F</td>\n",
       "      <td>ford motor credit co.</td>\n",
       "      <td>27</td>\n",
       "      <td>0.861</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.955</td>\n",
       "      <td>7.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>TWNE</td>\n",
       "      <td>towne mortgage company</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.949</td>\n",
       "      <td>7.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>AMSF</td>\n",
       "      <td>amerisave mortgage corporation</td>\n",
       "      <td>6</td>\n",
       "      <td>0.983</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.903</td>\n",
       "      <td>4.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>MRDH</td>\n",
       "      <td>meridian financial services, inc.</td>\n",
       "      <td>7</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.992</td>\n",
       "      <td>3.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>AFRM</td>\n",
       "      <td>affirm holdings, inc</td>\n",
       "      <td>140</td>\n",
       "      <td>0.862</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.999</td>\n",
       "      <td>2.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>ECPG</td>\n",
       "      <td>encore capital group inc.</td>\n",
       "      <td>354</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-10.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>WSPCF</td>\n",
       "      <td>w&amp;a intermediate co., llc</td>\n",
       "      <td>38</td>\n",
       "      <td>0.889</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.924</td>\n",
       "      <td>-10.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>VLY</td>\n",
       "      <td>valley national bancorp</td>\n",
       "      <td>11</td>\n",
       "      <td>0.622</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-11.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>TRU</td>\n",
       "      <td>transunion intermediate holdings, inc.</td>\n",
       "      <td>58625</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.985</td>\n",
       "      <td>-11.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>SNV</td>\n",
       "      <td>synovus bank</td>\n",
       "      <td>35</td>\n",
       "      <td>0.774</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-11.489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month_end ticker                                 company  \\\n",
       "10  2024-10-27      F                   ford motor credit co.   \n",
       "194 2024-10-27   TWNE                  towne mortgage company   \n",
       "97  2024-10-27   AMSF          amerisave mortgage corporation   \n",
       "221 2024-10-27   MRDH       meridian financial services, inc.   \n",
       "101 2024-10-27   AFRM                    affirm holdings, inc   \n",
       "..         ...    ...                                     ...   \n",
       "13  2024-10-27   ECPG               encore capital group inc.   \n",
       "180 2024-10-27  WSPCF               w&a intermediate co., llc   \n",
       "204 2024-10-27    VLY                 valley national bancorp   \n",
       "192 2024-10-27    TRU  transunion intermediate holdings, inc.   \n",
       "156 2024-10-27    SNV                            synovus bank   \n",
       "\n",
       "     complaint_count  culpability_score  complaint_score  grievance_score  \\\n",
       "10                27              0.861           -0.214            0.139   \n",
       "194                5              0.956            0.041           -0.064   \n",
       "97                 6              0.983           -0.085            0.105   \n",
       "221                7              0.870           -0.222            0.136   \n",
       "101              140              0.862           -0.232            0.008   \n",
       "..               ...                ...              ...              ...   \n",
       "13               354              0.230           -0.232            0.111   \n",
       "180               38              0.889           -0.218            0.124   \n",
       "204               11              0.622           -0.274           -0.350   \n",
       "192            58625              0.238           -0.256            0.008   \n",
       "156               35              0.774           -0.243           -0.141   \n",
       "\n",
       "     total_risk_rating  similarity  anomaly_score  \n",
       "10               0.262       0.955          7.347  \n",
       "194              0.311       0.949          7.254  \n",
       "97               0.335       0.903          4.284  \n",
       "221              0.261       0.992          3.257  \n",
       "101              0.213       0.999          2.771  \n",
       "..                 ...         ...            ...  \n",
       "13               0.036       0.999        -10.603  \n",
       "180              0.265       0.924        -10.916  \n",
       "204             -0.001       1.000        -11.324  \n",
       "192             -0.003       0.985        -11.394  \n",
       "156              0.130       0.982        -11.489  \n",
       "\n",
       "[128 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representation.sort_values(\"anomaly_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10760c01-635a-4736-8105-78722f8f66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and reorder columns\n",
    "df_risk = final_representation.copy()\n",
    "selected_columns = [\n",
    "    'ticker', \n",
    "    'company',\n",
    "    'complaint_count',\n",
    "    'total_risk_rating',\n",
    "    'anomaly_score',\n",
    "    'culpability_score',\n",
    "    'complaint_score',\n",
    "    'grievance_score',\n",
    "    'similarity'\n",
    "]\n",
    "\n",
    "df_risk = df_risk[selected_columns].rename(columns={'anomaly_score': 'risk_change'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3419997c-048e-44f8-a7a6-2b3201791374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk[[\"total_risk_rating\",\"culpability_score\",\"complaint_score\",\"grievance_score\"]] = df_risk[[\"total_risk_rating\",\"culpability_score\",\"complaint_score\",\"grievance_score\"]]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "906ac192-8214-4514-b5e7-7370cac5a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk = df_risk.sort_values('risk_change', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a25d7213-b3be-4caf-ba5a-3747bff1d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import locale\n",
    "\n",
    "# Set locale to US English\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "\n",
    "\n",
    "def get_week_ending_label(reference_date=None):\n",
    "    \"\"\"\n",
    "    Returns a formatted string indicating the week ending on the last Friday relative to the reference date.\n",
    "\n",
    "    Args:\n",
    "        reference_date (datetime.date, optional): The date to reference. Defaults to today.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string like \"Week ending Friday 25th October, 2024\"\n",
    "    \"\"\"\n",
    "    if reference_date is None:\n",
    "        reference_date = datetime.date.today()\n",
    "    \n",
    "    def get_ordinal(n):\n",
    "        if 11 <= n % 100 <= 13:\n",
    "            suffix = 'th'\n",
    "        else:\n",
    "            suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(n % 10, 'th')\n",
    "        return f\"{n}{suffix}\"\n",
    "    \n",
    "    days_since_friday = (reference_date.weekday() - 4) % 7\n",
    "    last_friday = reference_date - datetime.timedelta(days=days_since_friday)\n",
    "    day_with_ordinal = get_ordinal(last_friday.day)\n",
    "    formatted_date = f\"Week ending {last_friday.strftime('%A')} {day_with_ordinal} {last_friday.strftime('%B')}, {last_friday.year}\"\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "# Usage\n",
    "formatted_week_label = get_week_ending_label()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4da6891-d18a-44a3-9f56-60fb0c64bd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/ZISBA/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "from datawrapper import Datawrapper\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Datawrapper\n",
    "dw = Datawrapper(access_token=\"your_token\")\n",
    "\n",
    "# Create the chart\n",
    "chart = dw.create_chart(\n",
    "    title=\"Financial Institution Risk Analysis\",\n",
    "    chart_type=\"tables\"\n",
    ")\n",
    "\n",
    "# Add the data to the chart\n",
    "dw.add_data(chart['id'], data=df_risk)\n",
    "\n",
    "# Configure visualization properties\n",
    "properties = {\n",
    "    \"visualize\": {\n",
    "        \"dark-mode-invert\": True,\n",
    "        \"perPage\": 10,\n",
    "        \"columns\": {\n",
    "            \"ticker\": {\n",
    "                \"align\": \"left\",\n",
    "                \"title\": \"Ticker\",\n",
    "                \"width\": \"100\",\n",
    "                \"fixedWidth\": False\n",
    "            },\n",
    "            \"company\": {\n",
    "                \"align\": \"left\",\n",
    "                \"title\": \"Company\",\n",
    "                \"width\": \"200\",\n",
    "                \"fixedWidth\": False\n",
    "            },\n",
    "            \"complaint_count\": {\n",
    "                \"title\": \"Complaints\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"0,0\"\n",
    "            },\n",
    "            \"total_risk_rating\": {\n",
    "                \"title\": \"Risk Rating\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"+0.000\"\n",
    "            },\n",
    "            \"risk_change\": {\n",
    "                \"title\": \"Risk Change\",\n",
    "                \"align\": \"right\",\n",
    "                \"width\": 0.66,\n",
    "                \"format\": \"+0.000\",\n",
    "                \"showAsBar\": True,\n",
    "                \"barColor\": 7,\n",
    "                \"barColorNegative\": 1,\n",
    "                \"fixedWidth\": True,\n",
    "                \"minWidth\": 35\n",
    "            },\n",
    "            \"culpability_score\": {\n",
    "                \"title\": \"Culpability\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"0.000\"\n",
    "            },\n",
    "            \"complaint_score\": {\n",
    "                \"title\": \"Complaint\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"+0.000\"\n",
    "            },\n",
    "            \"grievance_score\": {\n",
    "                \"title\": \"Grievance\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"+0.000\"\n",
    "            },\n",
    "            \"similarity\": {\n",
    "                \"title\": \"Similarity\",\n",
    "                \"align\": \"right\",\n",
    "                \"format\": \"0.000\"\n",
    "            }\n",
    "        },\n",
    "        \"header\": {\n",
    "            \"style\": {\n",
    "                \"bold\": True,\n",
    "                \"fontSize\": 0.9,\n",
    "                \"color\": \"#494949\"\n",
    "            },\n",
    "            \"borderBottom\": \"2px\",\n",
    "            \"borderBottomColor\": \"#333333\"\n",
    "        },\n",
    "        \"pagination\": {\n",
    "            \"enabled\": True,\n",
    "            \"position\": \"bottom\",\n",
    "            \"pagesPerScreen\": 10\n",
    "        },\n",
    "        \"striped\": True,\n",
    "        \"markdown\": False,\n",
    "        \"showHeader\": True,\n",
    "        \"compactMode\": True,\n",
    "        \"firstRowIsHeader\": False,\n",
    "        \"firstColumnIsSticky\": True,\n",
    "        \"mergeEmptyCells\": False,\n",
    "        \"sortBy\": \"risk_change\",\n",
    "        \"sortDirection\": \"desc\"\n",
    "    },\n",
    "    \"describe\": {\n",
    "        \"intro\": (f\"Analysis of financial institutions' risk metrics and complaint data.. Sorted by risk change (highest to lowest). {formatted_week_label}\"\n",
    "                 \" Derived from <a href='https://docs.sov.ai/realtime-datasets/sectorial-datasets/cfpb-complaints'>Sov.ai™ Complaints</a> datasets.\"),\n",
    "        \n",
    "        \"byline\": \"\",\n",
    "        \"source-name\": \"Consumer Complaints Database\",\n",
    "        \"hide-title\": False\n",
    "    },\n",
    "    \"publish\": {\n",
    "        \"embed-width\": 1000,\n",
    "        \"embed-height\": 800,\n",
    "        \"blocks\": {\n",
    "            \"logo\": {\"enabled\": False},\n",
    "            \"embed\": False,\n",
    "            \"download-pdf\": False,\n",
    "            \"download-svg\": False,\n",
    "            \"get-the-data\": True,\n",
    "            \"download-image\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update the chart with the properties\n",
    "dw.update_chart(\n",
    "    chart['id'],\n",
    "    metadata=properties\n",
    ")\n",
    "\n",
    "# Publish the chart\n",
    "dw.publish_chart(chart['id'])\n",
    "\n",
    "# Get the published URL\n",
    "published_url = dw.get_chart_display_urls(chart['id'])\n",
    "print(\"Published Chart URL:\", published_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b2cad-2da3-49f1-ba04-52481e9a8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define title\n",
    "page_title = \"Predict a Mockingbird\"\n",
    "\n",
    "# Define content sections using the content_sections dictionary\n",
    "content_sections = {\n",
    "    \"section_1\": {\n",
    "        \"heading\": \"Consumer Financial Complaints\",\n",
    "        \"content\": (\n",
    "            \"Here we investigate recent changes in risk for financial firms based on complaints they have received.\"\n",
    "            \" The mapping from ticker to names are not yet solved for this dataset, so use with caution.\"\n",
    "            \n",
    "        ),\n",
    "        \"url\": published_url[0][\"url\"],\n",
    "        \"list\": None\n",
    "    }\n",
    "\n",
    "    # Add more sections as needed\n",
    "}\n",
    "\n",
    "# Handle page creation or append\n",
    "handle_page_creation_or_append(page_title, DATABASE_ID, content_sections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
