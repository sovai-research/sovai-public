{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sovai[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed9f818-6707-4daa-8a41-ded5dac15988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up Notion credentials (hardcoded as per your request)\n",
    "NOTION_TOKEN = \"your_notion_token_here\"  # **Ensure this token is kept secure!**\n",
    "DATABASE_ID = \"your_database_id_here\"\n",
    "NOTION_VERSION = \"2022-06-28\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": NOTION_VERSION,\n",
    "}\n",
    "\n",
    "def create_page(title, database_id, children):\n",
    "    \"\"\"\n",
    "    Creates a new page in the specified Notion database.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        children (list): A list of block objects to include in the page.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    page_data = {\n",
    "        \"parent\": {\"database_id\": database_id},\n",
    "        \"properties\": {\n",
    "            \"Title\": {\n",
    "                \"title\": [\n",
    "                    {\n",
    "                        \"text\": {\n",
    "                            \"content\": title\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        \"children\": children\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.notion.com/v1/pages\", headers=headers, json=page_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def find_page_by_title(database_id, title):\n",
    "    \"\"\"\n",
    "    Searches the Notion database for a page with the specified title.\n",
    "\n",
    "    Args:\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        title (str): The title to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The page object if found, else None.\n",
    "    \"\"\"\n",
    "    query_url = f\"https://api.notion.com/v1/databases/{database_id}/query\"\n",
    "    query_data = {\n",
    "        \"filter\": {\n",
    "            \"property\": \"Title\",\n",
    "            \"title\": {\n",
    "                \"equals\": title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(query_url, headers=headers, json=query_data)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to query database:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        return None\n",
    "\n",
    "    results = response.json().get(\"results\")\n",
    "    if results:\n",
    "        return results[0]  # Assuming titles are unique\n",
    "    return None\n",
    "\n",
    "\n",
    "def append_to_page(page_id, children):\n",
    "    \"\"\"\n",
    "    Appends new blocks to an existing Notion page.\n",
    "\n",
    "    Args:\n",
    "        page_id (str): The ID of the page to append to.\n",
    "        children (list): A list of block objects to append.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    append_url = f\"https://api.notion.com/v1/blocks/{page_id}/children\"\n",
    "    append_data = {\n",
    "        \"children\": children\n",
    "    }\n",
    "    response = requests.patch(append_url, headers=headers, json=append_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def build_content_from_dict(content_dict):\n",
    "    \"\"\"\n",
    "    Builds Notion content blocks from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing content definitions.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Add Heading\n",
    "    if \"heading\" in content_dict and content_dict[\"heading\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"heading_2\",\n",
    "                \"heading_2\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"heading\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Add Content\n",
    "    if \"content\" in content_dict and content_dict[\"content\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"content\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add List Items (Bullet Points)\n",
    "    if \"list\" in content_dict and content_dict[\"list\"]:\n",
    "        list_blocks = build_bullet_list(content_dict[\"list\"])\n",
    "        children.extend(list_blocks)\n",
    "        \n",
    "    # Add URL as a Link\n",
    "    if \"url\" in content_dict and content_dict[\"url\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"url\"],\n",
    "                                \"link\": {\"url\": content_dict[\"url\"]}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "def build_bullet_list(items):\n",
    "    \"\"\"\n",
    "    Builds Notion bullet list blocks from a list of items.\n",
    "\n",
    "    Args:\n",
    "        items (list): A list of strings representing bullet points.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion bulleted list item block objects.\n",
    "    \"\"\"\n",
    "    bullet_blocks = []\n",
    "    for item in items:\n",
    "        bullet_blocks.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"bulleted_list_item\",\n",
    "                \"bulleted_list_item\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": item\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    return bullet_blocks\n",
    "\n",
    "\n",
    "def build_children_from_sections(content_sections):\n",
    "    \"\"\"\n",
    "    Iterates through the content sections dictionary and builds the children blocks.\n",
    "\n",
    "    Args:\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "    for key in sorted(content_sections.keys()):\n",
    "        section = content_sections[key]\n",
    "        section_blocks = build_content_from_dict(section)\n",
    "        children.extend(section_blocks)\n",
    "    return children\n",
    "\n",
    "\n",
    "def handle_page_creation_or_append(title, database_id, content_sections):\n",
    "    \"\"\"\n",
    "    Handles the logic to either create a new page or append content to an existing page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try: \n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    full_title = f\"{title} - {current_date}\"\n",
    "\n",
    "    # Build the content blocks\n",
    "    children = build_children_from_sections(content_sections)\n",
    "\n",
    "    # Check if the page already exists\n",
    "    existing_page = find_page_by_title(database_id, full_title)\n",
    "\n",
    "    if existing_page:\n",
    "        print(f\"Page '{full_title}' already exists. Appending new content to it.\")\n",
    "        page_id = existing_page[\"id\"]\n",
    "        response = append_to_page(page_id, children)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"New content appended successfully.\")\n",
    "            # Construct the page URL manually\n",
    "            # Note: Notion page URLs follow the format https://www.notion.so/{workspace}/{page_id}\n",
    "            # However, constructing the exact URL might require additional steps.\n",
    "            # Here, we'll provide a placeholder.\n",
    "            page_url = f\"https://www.notion.so/{page_id.replace('-', '')}\"\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to append new content:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f\"Page '{full_title}' does not exist. Creating a new page with the new content.\")\n",
    "        response = create_page(full_title, database_id, children)\n",
    "        \n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            page_url = response.json().get(\"url\", \"No URL returned\")\n",
    "            print(\"Page created successfully with the new content.\")\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to create page:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c6c93c-b180-43b9-9266-75887c4b58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f91727b-6a42-415c-9b64-02858b14f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_meta = pd.read_parquet(\"data/tickers.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f8ae34-4c20-495c-a60a-35572bf22b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_filter is your DataFrame\n",
    "\n",
    "def acquisition_filter():\n",
    "\n",
    "    df_filter = pd.read_parquet(\"https://storage.googleapis.com/sovai-public/concats/filters/latest.parquet\")\n",
    "    # Calculate the percentage difference between current price and moving averages\n",
    "    df_filter['perc_diff_50d_ma'] = np.abs((df_filter['current_price'] - df_filter['50_day_ma']) / df_filter['50_day_ma']) * 100\n",
    "    df_filter['perc_diff_200d_ma'] = np.abs((df_filter['current_price'] - df_filter['200_day_ma']) / df_filter['200_day_ma']) * 100\n",
    "    \n",
    "    # Define thresholds based on the data distribution\n",
    "    volatility_threshold = df_filter['volatility_30d'].quantile(0.05)  # Lower 25% volatility\n",
    "    volume_threshold = 10000  # Minimum average volume\n",
    "    \n",
    "    # Filter companies based on the criteria\n",
    "    stable_companies = df_filter[\n",
    "        (df_filter['volatility_30d'] <= volatility_threshold) &\n",
    "        (df_filter['weekly_return'].abs() <= 1) &\n",
    "        (df_filter['monthly_return'].abs() <= 2) &\n",
    "        (df_filter['perc_diff_50d_ma'] <= 2) &\n",
    "        # (df_filter['perc_diff_200d_ma'] <= 2) &\n",
    "        (df_filter['avg_volume_30d'] >= volume_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Select relevant columns for analysis\n",
    "    result = stable_companies[['current_price', '50_day_ma', '200_day_ma', 'volatility_30d', 'weekly_return', 'monthly_return', 'avg_volume_30d']]\n",
    "\n",
    "    tickers  = list(result.index.values)\n",
    "    return tickers\n",
    "remove_tickers = acquisition_filter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f90f249-f6e4-46b2-9725-d4d4d685910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msft = sov.data(\"breakout\", tickers=[\"MSFT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fa8b7f-1f20-42db-a4f1-a01727189dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sov.plot(\"breakout\", chart_type=\"predictions\", df=df_msft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d418c59-5e98-4290-9073-ce65eda23dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>future_returns</th>\n",
       "      <th>prediction</th>\n",
       "      <th>bottom_prediction</th>\n",
       "      <th>top_prediction</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>bottom_conformal</th>\n",
       "      <th>top_conformal</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">MSFT</th>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-16</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-17</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-18</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.387</td>\n",
       "      <td>-0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target  future_returns  prediction  bottom_prediction  \\\n",
       "ticker date                                                                \n",
       "MSFT   2021-08-12   1.000           0.139       0.170              0.158   \n",
       "       2021-08-13   1.000           0.140       0.170              0.159   \n",
       "       2021-08-16   1.000           0.136       0.169              0.160   \n",
       "       2021-08-17   1.000           0.150       0.170              0.160   \n",
       "       2021-08-18   1.000           0.156       0.171              0.160   \n",
       "...                   ...             ...         ...                ...   \n",
       "       2024-10-22   0.000          -0.002       0.292              0.278   \n",
       "       2024-10-23   1.000           0.005       0.261              0.248   \n",
       "       2024-10-24   1.000           0.004       0.262              0.248   \n",
       "       2024-10-25   0.000          -0.004       0.260              0.248   \n",
       "       2024-10-28   1.000           0.000       0.264              0.253   \n",
       "\n",
       "                   top_prediction  standard_deviation  bottom_conformal  \\\n",
       "ticker date                                                               \n",
       "MSFT   2021-08-12           0.175               0.006             0.000   \n",
       "       2021-08-13           0.175               0.006             0.000   \n",
       "       2021-08-16           0.175               0.006             0.000   \n",
       "       2021-08-17           0.175               0.006             0.000   \n",
       "       2021-08-18           0.180               0.006             0.000   \n",
       "...                           ...                 ...               ...   \n",
       "       2024-10-22           0.318               0.015             0.062   \n",
       "       2024-10-23           0.288               0.013             0.041   \n",
       "       2024-10-24           0.288               0.013             0.041   \n",
       "       2024-10-25           0.275               0.009             0.040   \n",
       "       2024-10-28           0.275               0.008             0.042   \n",
       "\n",
       "                   top_conformal  slope  \n",
       "ticker date                              \n",
       "MSFT   2021-08-12          0.387 -0.243  \n",
       "       2021-08-13          0.387 -0.239  \n",
       "       2021-08-16          0.387 -0.234  \n",
       "       2021-08-17          0.387 -0.228  \n",
       "       2021-08-18          0.387 -0.221  \n",
       "...                          ...    ...  \n",
       "       2024-10-22          0.479 -0.051  \n",
       "       2024-10-23          0.457 -0.054  \n",
       "       2024-10-24          0.458 -0.057  \n",
       "       2024-10-25          0.457 -0.058  \n",
       "       2024-10-28          0.458 -0.055  \n",
       "\n",
       "[808 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_msft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "468ac5e1-3e97-4740-96d6-a3e6d535480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           5,731 │               - │               - │\n",
      "│ Condition 1     │           3,486 │           2,245 │           3,486 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           5,731 │           2,245 │           3,486 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 3486 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: jOhH8\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/jOhH8/', 'name': 'For sharing'}]\n",
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           5,731 │               - │               - │\n",
      "│ Condition 1     │           3,486 │           2,245 │           3,486 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           5,731 │           2,245 │           3,486 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 3486 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: Bq1pt\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/Bq1pt/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "def get_breakout_date(frequency=\"difference\"):\n",
    "\n",
    "    df = sov.data(\"breakout\", frequency=frequency)\n",
    "\n",
    "    df = df[~df[\"ticker\"].isin(remove_tickers)]\n",
    "    \n",
    "    df = df.set_index([\"ticker\",\"date\"])\n",
    "    \n",
    "    df = df.filter([\"market_cap>100\"])\n",
    "\n",
    "    df[[\"prediction\",\"slope\"]] = df[[\"prediction\",\"slope\"]]*100\n",
    "\n",
    "    df = pd.merge(df[[\"prediction\",\"slope\"]].reset_index(),tickers_meta[[\"ticker\",\"sector\",\"industry\"]], on=\"ticker\", how=\"left\")\n",
    "\n",
    "    df = df[df[\"industry\"]!=\"Shell Companies\"].drop(columns=[\"industry\"])\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = df.rename(columns={\"slope\":\"slopebreak\", \"prediction\":\"predictbreak\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def create_sector_ranking(df, sort_column='sansmarket', top_n=10, select='both'):\n",
    "    def make_clickable(ticker):\n",
    "        url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "        return f'<a href=\"{url}\" target=\"_blank\">{ticker}</a>'\n",
    "    \n",
    "    # Ensure we're working with the latest date\n",
    "    latest_date = df['date'].max()\n",
    "    df_latest = df[df['date'] == latest_date]\n",
    "    \n",
    "    # Group by sector and get top N largest and smallest for each sector\n",
    "    grouped = df_latest.groupby('sector')\n",
    "    top_n_df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        if select in ['largest', 'both']:\n",
    "            top_largest = group.nlargest(top_n, sort_column)\n",
    "            top_largest = top_largest.copy()\n",
    "            top_largest['rank_type'] = 'Largest'\n",
    "            top_largest['rank'] = range(1, len(top_largest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_largest])\n",
    "        \n",
    "        if select in ['smallest', 'both']:\n",
    "            top_smallest = group.nsmallest(top_n, sort_column)\n",
    "            top_smallest = top_smallest.copy()\n",
    "            top_smallest['rank_type'] = 'Smallest'\n",
    "            top_smallest['rank'] = range(1, len(top_smallest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_smallest])\n",
    "    \n",
    "    # Format the sort_column to two decimal places\n",
    "    top_n_df[sort_column] = top_n_df[sort_column].map(\"{:.2f}\".format)\n",
    "    \n",
    "    # Make tickers clickable\n",
    "    top_n_df['ticker'] = top_n_df['ticker'].apply(make_clickable)\n",
    "    \n",
    "    # Sort the DataFrame for better organization\n",
    "    top_n_df.sort_values(['sector', 'rank_type', 'rank'], inplace=True)\n",
    "    \n",
    "    # Create a pivot table with the rank_type and rank as multi-index\n",
    "    top_n_pivot = top_n_df.pivot_table(index=['rank_type', 'rank'], \n",
    "                                      columns='sector', \n",
    "                                      values=[sort_column, 'ticker'],\n",
    "                                      aggfunc='first')\n",
    "    top_n_pivot = top_n_pivot.swaplevel(axis=1).sort_index(axis=1, level=0)\n",
    "    \n",
    "    # Prepare the data for Datawrapper format\n",
    "    output = io.StringIO()\n",
    "    \n",
    "    # Write the first row (sector names)\n",
    "    sectors = top_n_pivot.columns.get_level_values(0).unique()\n",
    "    output.write('Type,Rank,')\n",
    "    for sector in sectors:\n",
    "        output.write(f'~~~{sector}~~~,,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the second row (sans_market and ticker)\n",
    "    output.write(', ,')\n",
    "    for _ in sectors:\n",
    "        output.write(f'{sort_column},Ticker,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the data rows\n",
    "    for (rank_type, rank), row in top_n_pivot.iterrows():\n",
    "        output.write(f'{rank_type},{rank},')\n",
    "        for sector in sectors:\n",
    "            sans_market = row.get((sector, sort_column), '')\n",
    "            ticker = row.get((sector, 'ticker'), '')\n",
    "            output.write(f'{sans_market},{ticker},')\n",
    "        output.write('\\n')\n",
    "    \n",
    "    # Get the CSV string\n",
    "    csv_string = output.getvalue()\n",
    "    output.close()\n",
    "    \n",
    "    return csv_string\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# Unified configuration dictionary\n",
    "MODEL_CONFIG = {\n",
    "    # 'sansmarket': {\n",
    "    #     'model_name': \"Sans Market Model\",\n",
    "    #     'intro': (\n",
    "    #         \"The Sans Market model has fundamental accounting values pointing to bankruptcy, \"\n",
    "    #         \"but not the market price and behaviour. It is a leading indicator with good short potential | \"\n",
    "    #         '<a href=\"https://sov.ai\">Sov.ai™</a>'\n",
    "    #     ),\n",
    "    #     'start_title': {\n",
    "    #         True: \"Change in Bankruptcy Prediction\",\n",
    "    #         False: \"Level of Bankruptcy Prediction\"\n",
    "    #     },\n",
    "    #     'data_function': get_bankruptcy_date,\n",
    "    #     'title_template': \"{start_title} - {model_name} ({month_year})\"\n",
    "    # },\n",
    "    # 'probability': {\n",
    "    #     'model_name': \"Ensemble Model\",\n",
    "    #     'intro': (\n",
    "    #         \"The Ensemble Model uses deep learning and other models and multiple datasets to predict bankruptcy, \"\n",
    "    #         \"it is a concurrent indicator with reasonable short potential | \"\n",
    "    #         '<a href=\"https://sov.ai\">Sov.ai™</a>'\n",
    "    #     ),\n",
    "    #     'start_title': {\n",
    "    #         True: \"Change in Bankruptcy Prediction\",\n",
    "    #         False: \"Level of Bankruptcy Prediction\"\n",
    "    #     },\n",
    "    #     'data_function': get_bankruptcy_date,\n",
    "    #     'title_template': \"{start_title} - {model_name} ({month_year})\"\n",
    "    # },\n",
    "    'predictbreak': {\n",
    "        'model_name': \"Breakout Prediction Model\",\n",
    "        'intro': (\n",
    "            \"This model uses deep learning and other techniques to predict breakout direction on a daily basis. \"\n",
    "            \"For daily updates, see sov.ai | <a href=\\\"https://docs.sov.ai/realtime-datasets/equity-datasets/price-breakout\\\">Sov.ai™ Breakout</a>\"\n",
    "        ),\n",
    "        'start_title': {\n",
    "            True: \"Change in Predicted Breakout\",\n",
    "            False: \"Level of Breakout Prediction\"\n",
    "        },\n",
    "        'data_function': get_breakout_date,\n",
    "        'title_template': \"{start_title} - {model_name} ({month_year})\"\n",
    "    },\n",
    "    'slopebreak': {\n",
    "        'model_name': \"Slope Change Model\",\n",
    "        'intro': (\n",
    "            \"This model looks for daily changes in the slope (i.e., rate of change in the breakout direction). \"\n",
    "            \"For daily updates, see sov.ai | <a href=\\\"https://docs.sov.ai/realtime-datasets/equity-datasets/price-breakout\\\">Sov.ai™ Breakout</a>\"\n",
    "        ),\n",
    "        'start_title': {\n",
    "            True: \"Change in Predicted Slope\",\n",
    "            False: \"Level of Slope Prediction\"\n",
    "        },\n",
    "        'data_function': get_breakout_date,\n",
    "        'title_template': \"{start_title} - {model_name} ({month_year})\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_title_and_intro(sort_column, frequency):\n",
    "    \"\"\"\n",
    "    Generates the title, retrieves the intro, and returns the data function based on sort_column and frequency.\n",
    "    \n",
    "    Parameters:\n",
    "    - sort_column (str): The column to sort by.\n",
    "    - frequency (bool): Determines the start title based on change or level.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (title, intro, data_function)\n",
    "    \"\"\"\n",
    "    if sort_column not in MODEL_CONFIG:\n",
    "        valid_columns = ', '.join(MODEL_CONFIG.keys())\n",
    "        raise ValueError(f\"Invalid sort_column: '{sort_column}'. Available options are: {valid_columns}\")\n",
    "    \n",
    "    config = MODEL_CONFIG[sort_column]\n",
    "    \n",
    "    # Convert frequency to boolean; treat None as False\n",
    "    frequency_bool = bool(frequency)\n",
    "    \n",
    "    # Get the appropriate start_title based on frequency\n",
    "    start_title = config['start_title'].get(frequency_bool, f\"{config['model_name']} Prediction\")\n",
    "    \n",
    "    # Get current date in \"Month Year\" format\n",
    "    current_date = datetime.now()\n",
    "    month_year = current_date.strftime(\"%B %Y\")  # e.g., \"October 2024\"\n",
    "    \n",
    "    # Construct the full title using the template\n",
    "    title = config['title_template'].format(\n",
    "        start_title=start_title,\n",
    "        model_name=config['model_name'],\n",
    "        month_year=month_year\n",
    "    )\n",
    "    \n",
    "    # Get the intro text\n",
    "    intro = config['intro']\n",
    "    \n",
    "    # Get the data function\n",
    "    data_function = config['data_function']\n",
    "    \n",
    "    return title, intro, data_function\n",
    "\n",
    "\n",
    "\n",
    "from datawrapper import Datawrapper\n",
    "from IPython.display import IFrame\n",
    "from datetime import datetime\n",
    "\n",
    "def get_or_create_chart(dw, title, chart_type):\n",
    "    # Try to find an existing chart with the given title\n",
    "    charts = dw.get_charts(search=title, limit=1)\n",
    "\n",
    "    charts['total'] = 0 ##  Force to remove update function\n",
    "    \n",
    "    if charts['total'] > 0:\n",
    "        # If a chart is found, return its ID\n",
    "        print(\"Existing chart found:\")\n",
    "        return charts['list'][0]['id']\n",
    "    else:\n",
    "        # If no chart is found, create a new one\n",
    "        print(\"No existing chart found. Creating a new one.\")\n",
    "        new_chart = dw.create_chart(title=title, chart_type=chart_type)\n",
    "        print(\"New chart created:\")\n",
    "        return new_chart['id']\n",
    "\n",
    "\n",
    "\n",
    "def get_color_scheme(selection):\n",
    "    if selection == \"largest\":\n",
    "        return [\n",
    "            {\"color\": \"#f0f9e8\", \"position\": 0},\n",
    "            {\"color\": \"#b6e3bb\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#75c8c5\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#4ba8c9\", \"position\": 0.5},\n",
    "            {\"color\": \"#2989bd\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#0a6aad\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#254b8c\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"smallest\":\n",
    "        return [\n",
    "            {\"color\": \"#fff5f0\", \"position\": 0},\n",
    "            {\"color\": \"#fee0d2\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#fcbba1\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#fb6a4a\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#ef3b2c\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#cb181d\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"both\":\n",
    "        return [\n",
    "            {\"color\": \"#f0f9e8\", \"position\": 0},\n",
    "            {\"color\": \"#b6e3bb\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#75c8c5\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#fb6a4a\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#ef3b2c\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#cb181d\", \"position\": 1}\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"selection must be either 'largest' or 'smallest'\")\n",
    "\n",
    "# Usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sort_table(sort_column='slopebreak', frequency=None, top_n=10, selection=\"largest\"):\n",
    "    \"\"\"\n",
    "    Creates and updates a Datawrapper table with appropriate heatmap settings.\n",
    "    \n",
    "    Parameters:\n",
    "    - sort_column (str): The column to sort by ('slopebreak' or 'predictbreak').\n",
    "    - frequency (bool or None): Determines if it's a change or level metric.\n",
    "    - top_n (int): Number of top entries per sector.\n",
    "    - selection (str): 'largest', 'smallest', or 'both'.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (public_url, IFrame object)\n",
    "    \"\"\"\n",
    "    # Generate title, intro, and data function based on sort_column and frequency\n",
    "    title, intro, data_func = generate_title_and_intro(sort_column, frequency)\n",
    "\n",
    "    # Fetch and process the data\n",
    "    df = data_func(frequency=frequency)\n",
    "    csv_data = create_sector_ranking(df, sort_column=sort_column, top_n=top_n, select=selection)\n",
    "\n",
    "    # Initialize Datawrapper with your access token\n",
    "    dw = Datawrapper(access_token=\"your_token\")\n",
    "\n",
    "    # Create or get existing chart\n",
    "    chart_id = get_or_create_chart(dw, title, \"tables\")\n",
    "    print(f\"Chart ID: {chart_id}\")\n",
    "\n",
    "    try:\n",
    "        # Update the chart with new data\n",
    "        dw.add_data(chart_id, data=csv_data)\n",
    "        print(\"Data added successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Define sectors based on your data\n",
    "    sectors = ['Energy', 'Utilities', 'Healthcare', 'Technology', 'Industrials', \n",
    "               'Real Estate', 'Basic Materials', 'Consumer Cyclical', \n",
    "               'Consumer Defensive', 'Financial Services', 'Communication Services']\n",
    "\n",
    "    # Dynamically generate heatmap color palette\n",
    "    # Adjust the colors and positions as per your requirements\n",
    "    heatmap_colors = [\n",
    "        {\"color\": \"#b2182b\", \"position\": 0},\n",
    "        {\"color\": \"#ef8a62\", \"position\": 0.16666666666666666},\n",
    "        {\"color\": \"#fddbc7\", \"position\": 0.3333333333333333},\n",
    "        {\"color\": \"#f8f6e9\", \"position\": 0.5},\n",
    "        {\"color\": \"#d1e5f0\", \"position\": 0.6666666666666666},\n",
    "        {\"color\": \"#67a9cf\", \"position\": 0.8333333333333334},\n",
    "        {\"color\": \"#2166ac\", \"position\": 1}\n",
    "    ]\n",
    "\n",
    "    # Determine appropriate heatmap ranges based on data\n",
    "    sort_min = df[sort_column].min()\n",
    "    sort_max = df[sort_column].max()\n",
    "\n",
    "    # Prepare the 'columns' configuration\n",
    "    columns_config = {\n",
    "        \"\": {\"align\": \"left\", \"title\": \"Rank\", \"width\": \"auto\"},\n",
    "        \"Type\": {\"align\": \"left\", \"title\": \"Type\", \"width\": \"auto\"},\n",
    "    }\n",
    "\n",
    "    for sector in sectors:\n",
    "        columns_config[f\"~~~{sector}~~~\"] = {\n",
    "            \"format\": \"0.[00]%\",  # Adjust format as needed\n",
    "            \"heatmap\": {\n",
    "                \"enabled\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Define the updated_metadata with detailed heatmap settings\n",
    "    updated_metadata = {\n",
    "        \"data\": {\n",
    "            \"transpose\": False,\n",
    "            \"vertical-header\": True,\n",
    "            \"horizontal-header\": True,\n",
    "            \"upload-method\": \"copy\"\n",
    "        },\n",
    "        \"visualize\": {\n",
    "            \"dark-mode-invert\": True,\n",
    "            \"perPage\": 10,  # Items per page\n",
    "            \"pagination\": {\n",
    "                \"enabled\": True,\n",
    "                \"position\": \"bottom\",\n",
    "                \"pagesPerScreen\": 10\n",
    "            },\n",
    "            \"highlighted-series\": [],\n",
    "            \"highlighted-values\": [],\n",
    "            \"sharing\": {\n",
    "                \"enabled\": False,\n",
    "                \"url\": f\"https://www.datawrapper.de/_/{chart_id}\",\n",
    "                \"auto\": False\n",
    "            },\n",
    "            \"rows\": {\n",
    "                \"header\": {\"rows\": 2},\n",
    "                \"row--1\": {\n",
    "                    \"style\": {\n",
    "                        \"bold\": False,\n",
    "                        \"color\": False,\n",
    "                        \"italic\": False,\n",
    "                        \"fontSize\": 1,\n",
    "                        \"underline\": False,\n",
    "                        \"background\": False\n",
    "                    },\n",
    "                    \"format\": \"0,0.[00]\",\n",
    "                    \"moveTo\": \"top\",\n",
    "                    \"sticky\": False,\n",
    "                    \"moveRow\": False,\n",
    "                    \"stickTo\": \"top\",\n",
    "                    \"borderTop\": \"none\",\n",
    "                    \"borderBottom\": \"none\",\n",
    "                    \"borderTopColor\": \"#333333\",\n",
    "                    \"overrideFormat\": False,\n",
    "                    \"borderBottomColor\": \"#333333\"\n",
    "                }\n",
    "            },\n",
    "            \"header\": {\n",
    "                \"style\": {\n",
    "                    \"bold\": True,\n",
    "                    \"color\": False,\n",
    "                    \"italic\": False,\n",
    "                    \"fontSize\": 1.1,\n",
    "                    \"background\": False\n",
    "                },\n",
    "                \"borderTop\": \"none\",\n",
    "                \"borderBottom\": \"2px\",\n",
    "                \"borderTopColor\": \"#333333\",\n",
    "                \"borderBottomColor\": \"#333333\"\n",
    "            },\n",
    "            \"legend\": {\n",
    "                \"size\": 170,\n",
    "                \"labels\": \"ranges\",\n",
    "                \"enabled\": False,\n",
    "                \"reverse\": False,\n",
    "                \"labelMax\": \"high\",\n",
    "                \"labelMin\": \"low\",\n",
    "                \"position\": \"above\",\n",
    "                \"interactive\": False,\n",
    "                \"labelCenter\": \"medium\",\n",
    "                \"labelFormat\": \"0,0.[00]\",\n",
    "                \"customLabels\": []\n",
    "            },\n",
    "            \"columns\": columns_config,\n",
    "            \"heatmap\": {\n",
    "                \"map\": {},\n",
    "                \"mode\": \"continuous\",\n",
    "                \"stops\": \"equidistant\",\n",
    "                \"palette\": 0,\n",
    "                \"rangeMax\": \"\",  # Let Datawrapper auto-calculate or set manually\n",
    "                \"rangeMin\": \"\",\n",
    "                \"stopCount\": 5,\n",
    "                \"hideValues\": False,\n",
    "                \"customStops\": [],\n",
    "                \"rangeCenter\": \"30\",  # Adjust based on your data\n",
    "                \"categoryOrder\": [],\n",
    "                \"interpolation\": \"deciles\",\n",
    "                \"categoryLabels\": {},\n",
    "                \"colors\": heatmap_colors  # Custom color palette\n",
    "            },\n",
    "            \"perPage\": 10,\n",
    "            \"striped\": False,\n",
    "            \"markdown\": True,\n",
    "            \"showRank\": False,\n",
    "            \"sortTable\": False,\n",
    "            \"pagination\": {\"enabled\": True, \"position\": \"bottom\"},\n",
    "            \"searchable\": False,\n",
    "            \"showHeader\": True,\n",
    "            \"compactMode\": True,\n",
    "            \"sortDirection\": \"desc\",\n",
    "            \"chart-type-set\": True,\n",
    "            \"mobileFallback\": False,\n",
    "            \"mergeEmptyCells\": True,\n",
    "            \"firstRowIsHeader\": True,\n",
    "            \"firstColumnIsSticky\": True\n",
    "        },\n",
    "        \"describe\": {\n",
    "            \"intro\": intro,\n",
    "            \"byline\": \"\",\n",
    "            \"source-name\": \"\",\n",
    "            \"source-url\": \"\",\n",
    "            \"hide-title\": False\n",
    "        },\n",
    "        \"publish\": {\n",
    "            \"embed-width\": 600,\n",
    "            \"embed-height\": 510,\n",
    "            \"blocks\": {\n",
    "                \"logo\": {\"enabled\": False},\n",
    "                \"embed\": False,\n",
    "                \"download-pdf\": False,\n",
    "                \"download-svg\": False,\n",
    "                \"get-the-data\": True,\n",
    "                \"download-image\": False\n",
    "            },\n",
    "            \"autoDarkMode\": False,\n",
    "            \"chart-height\": 395,\n",
    "            \"force-attribution\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Optionally, adjust 'rangeCenter' based on sort_column\n",
    "    if sort_column == 'slopebreak':\n",
    "        updated_metadata['visualize']['heatmap']['rangeCenter'] = \"0\"  # Example adjustment\n",
    "    elif sort_column == 'predictbreak':\n",
    "        updated_metadata['visualize']['heatmap']['rangeCenter'] = \"30\"  # Example adjustment\n",
    "\n",
    "    # Update the chart with the new metadata\n",
    "    try:\n",
    "        result = dw.update_chart(chart_id, metadata=updated_metadata)\n",
    "        print(\"Chart updated successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating chart: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Publish the updated chart\n",
    "    try:\n",
    "        publish_result = dw.publish_chart(chart_id)\n",
    "        print(\"Chart published successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error publishing chart: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve and print the published chart URL\n",
    "    try:\n",
    "        published_url = dw.get_chart_display_urls(chart_id)\n",
    "        print(\"Published Chart URL:\", published_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting chart URL: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the public URL from the publish result\n",
    "    public_url = publish_result[\"data\"][\"publicUrl\"]\n",
    "\n",
    "    # Display the chart within the notebook\n",
    "    return public_url, IFrame(src=public_url, width=1200, height=600)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "url_levels, frame  = create_sort_table(sort_column='slopebreak', frequency=None, top_n=40, selection=\"both\")\n",
    "\n",
    "# url_difference, frame  = create_sort_table(sort_column='predictbreak', frequency=\"difference\", top_n=40, selection=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16b14cfa-28cd-460f-8c25-6a6cac233391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           5,731 │               - │               - │\n",
      "│ Condition 1     │           3,486 │           2,245 │           3,486 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           5,731 │           2,245 │           3,486 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 3486 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: kQ5bI\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/kQ5bI/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "slope_change, frame  = create_sort_table(sort_column='slopebreak', frequency=\"difference\", top_n=40, selection=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eabbdb1-d9aa-47ec-8c3b-25b3d2cf9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 'Predict a Mockingbird - 2024-10-30' already exists. Appending new content to it.\n",
      "New content appended successfully.\n",
      "View your page here: https://www.notion.so/12f094f0f39581b4b996e912a2f7a7f4\n"
     ]
    }
   ],
   "source": [
    "# Define title\n",
    "page_title = \"Predict a Mockingbird\"\n",
    "\n",
    "# Define content sections using the content_sections dictionary\n",
    "content_sections = {\n",
    "    \"section_1\": {\n",
    "        \"heading\": \"Change in Breakout\",\n",
    "        \"content\": (\n",
    "            \"Using sophisticated machine learning models we track the predicted change in price breakouts\"\n",
    "            \". The implication of a change is that a stock has become more or less likely to go higher in price.\"\n",
    "            \n",
    "        ),\n",
    "        \"url\": url_difference,\n",
    "        \"list\": None\n",
    "    },\n",
    "\n",
    "    \"section_3\": {\n",
    "        \"heading\": \"Change in Slope\",\n",
    "        \"content\": (\n",
    "            \"A second order measure of the slope that is more sensitive to false positives but a faster detector in a predicted change in price. \"\n",
    "            \n",
    "        ),\n",
    "        \"url\": slope_change,\n",
    "        \"list\": None\n",
    "    },\n",
    "    # Add more sections as needed\n",
    "}\n",
    "\n",
    "# Handle page creation or append\n",
    "handle_page_creation_or_append(page_title, DATABASE_ID, content_sections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
