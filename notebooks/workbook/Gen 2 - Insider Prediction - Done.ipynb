{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sovai[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30413052-6f07-4b3d-991d-4bc3d9244754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up Notion credentials (hardcoded as per your request)\n",
    "NOTION_TOKEN = \"your_notion_token_here\"  # **Ensure this token is kept secure!**\n",
    "DATABASE_ID = \"your_database_id_here\"\n",
    "NOTION_VERSION = \"2022-06-28\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": NOTION_VERSION,\n",
    "}\n",
    "\n",
    "def create_page(title, database_id, children):\n",
    "    \"\"\"\n",
    "    Creates a new page in the specified Notion database.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        children (list): A list of block objects to include in the page.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    page_data = {\n",
    "        \"parent\": {\"database_id\": database_id},\n",
    "        \"properties\": {\n",
    "            \"Title\": {\n",
    "                \"title\": [\n",
    "                    {\n",
    "                        \"text\": {\n",
    "                            \"content\": title\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        \"children\": children\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.notion.com/v1/pages\", headers=headers, json=page_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def find_page_by_title(database_id, title):\n",
    "    \"\"\"\n",
    "    Searches the Notion database for a page with the specified title.\n",
    "\n",
    "    Args:\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        title (str): The title to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The page object if found, else None.\n",
    "    \"\"\"\n",
    "    query_url = f\"https://api.notion.com/v1/databases/{database_id}/query\"\n",
    "    query_data = {\n",
    "        \"filter\": {\n",
    "            \"property\": \"Title\",\n",
    "            \"title\": {\n",
    "                \"equals\": title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(query_url, headers=headers, json=query_data)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to query database:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        return None\n",
    "\n",
    "    results = response.json().get(\"results\")\n",
    "    if results:\n",
    "        return results[0]  # Assuming titles are unique\n",
    "    return None\n",
    "\n",
    "\n",
    "def append_to_page(page_id, children):\n",
    "    \"\"\"\n",
    "    Appends new blocks to an existing Notion page.\n",
    "\n",
    "    Args:\n",
    "        page_id (str): The ID of the page to append to.\n",
    "        children (list): A list of block objects to append.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    append_url = f\"https://api.notion.com/v1/blocks/{page_id}/children\"\n",
    "    append_data = {\n",
    "        \"children\": children\n",
    "    }\n",
    "    response = requests.patch(append_url, headers=headers, json=append_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def build_content_from_dict(content_dict):\n",
    "    \"\"\"\n",
    "    Builds Notion content blocks from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing content definitions.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Add Heading\n",
    "    if \"heading\" in content_dict and content_dict[\"heading\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"heading_2\",\n",
    "                \"heading_2\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"heading\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Add Content\n",
    "    if \"content\" in content_dict and content_dict[\"content\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"content\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add List Items (Bullet Points)\n",
    "    if \"list\" in content_dict and content_dict[\"list\"]:\n",
    "        list_blocks = build_bullet_list(content_dict[\"list\"])\n",
    "        children.extend(list_blocks)\n",
    "        \n",
    "    # Add URL as a Link\n",
    "    if \"url\" in content_dict and content_dict[\"url\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"url\"],\n",
    "                                \"link\": {\"url\": content_dict[\"url\"]}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "def build_bullet_list(items):\n",
    "    \"\"\"\n",
    "    Builds Notion bullet list blocks from a list of items.\n",
    "\n",
    "    Args:\n",
    "        items (list): A list of strings representing bullet points.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion bulleted list item block objects.\n",
    "    \"\"\"\n",
    "    bullet_blocks = []\n",
    "    for item in items:\n",
    "        bullet_blocks.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"bulleted_list_item\",\n",
    "                \"bulleted_list_item\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": item\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    return bullet_blocks\n",
    "\n",
    "\n",
    "def build_children_from_sections(content_sections):\n",
    "    \"\"\"\n",
    "    Iterates through the content sections dictionary and builds the children blocks.\n",
    "\n",
    "    Args:\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "    for key in sorted(content_sections.keys()):\n",
    "        section = content_sections[key]\n",
    "        section_blocks = build_content_from_dict(section)\n",
    "        children.extend(section_blocks)\n",
    "    return children\n",
    "\n",
    "\n",
    "def handle_page_creation_or_append(title, database_id, content_sections):\n",
    "    \"\"\"\n",
    "    Handles the logic to either create a new page or append content to an existing page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    full_title = f\"{title} - {current_date}\"\n",
    "\n",
    "    # Build the content blocks\n",
    "    children = build_children_from_sections(content_sections)\n",
    "\n",
    "    # Check if the page already exists\n",
    "    existing_page = find_page_by_title(database_id, full_title)\n",
    "\n",
    "    if existing_page:\n",
    "        print(f\"Page '{full_title}' already exists. Appending new content to it.\")\n",
    "        page_id = existing_page[\"id\"]\n",
    "        response = append_to_page(page_id, children)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"New content appended successfully.\")\n",
    "            # Construct the page URL manually\n",
    "            # Note: Notion page URLs follow the format https://www.notion.so/{workspace}/{page_id}\n",
    "            # However, constructing the exact URL might require additional steps.\n",
    "            # Here, we'll provide a placeholder.\n",
    "            page_url = f\"https://www.notion.so/{page_id.replace('-', '')}\"\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to append new content:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f\"Page '{full_title}' does not exist. Creating a new page with the new content.\")\n",
    "        response = create_page(full_title, database_id, children)\n",
    "        \n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            page_url = response.json().get(\"url\", \"No URL returned\")\n",
    "            print(\"Page created successfully with the new content.\")\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to create page:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4c6c93c-b180-43b9-9266-75887c4b58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f91727b-6a42-415c-9b64-02858b14f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_meta = pd.read_parquet(\"data/tickers.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9f8ae34-4c20-495c-a60a-35572bf22b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_filter is your DataFrame\n",
    "\n",
    "def acquisition_filter():\n",
    "\n",
    "    df_filter = pd.read_parquet(\"https://storage.googleapis.com/sovai-public/concats/filters/latest.parquet\")\n",
    "    # Calculate the percentage difference between current price and moving averages\n",
    "    df_filter['perc_diff_50d_ma'] = np.abs((df_filter['current_price'] - df_filter['50_day_ma']) / df_filter['50_day_ma']) * 100\n",
    "    df_filter['perc_diff_200d_ma'] = np.abs((df_filter['current_price'] - df_filter['200_day_ma']) / df_filter['200_day_ma']) * 100\n",
    "    \n",
    "    # Define thresholds based on the data distribution\n",
    "    volatility_threshold = df_filter['volatility_30d'].quantile(0.05)  # Lower 25% volatility\n",
    "    volume_threshold = 10000  # Minimum average volume\n",
    "    \n",
    "    # Filter companies based on the criteria\n",
    "    stable_companies = df_filter[\n",
    "        (df_filter['volatility_30d'] <= volatility_threshold) &\n",
    "        (df_filter['weekly_return'].abs() <= 1) &\n",
    "        (df_filter['monthly_return'].abs() <= 2) &\n",
    "        (df_filter['perc_diff_50d_ma'] <= 2) &\n",
    "        # (df_filter['perc_diff_200d_ma'] <= 2) &\n",
    "        (df_filter['avg_volume_30d'] >= volume_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Select relevant columns for analysis\n",
    "    result = stable_companies[['current_price', '50_day_ma', '200_day_ma', 'volatility_30d', 'weekly_return', 'monthly_return', 'avg_volume_30d']]\n",
    "\n",
    "    tickers  = list(result.index.values)\n",
    "    return tickers\n",
    "remove_tickers = acquisition_filter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f2676af-dd84-4c42-ab54-c677714492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insider_flows_date(frequency=\"difference\"):\n",
    "\n",
    "    df = sov.data(\"insider/trading\", frequency=frequency)[[\"flow_prediction\"]]\n",
    "\n",
    "\n",
    "    # df = df[~df[\"ticker\"].isin(remove_tickers)]\n",
    "    \n",
    "    # df = df.set_index([\"ticker\",\"date\"])\n",
    "    \n",
    "    df = df.filter([\"market_cap>100\"])\n",
    "    \n",
    "    df[\"flow_prediction\"] = df[\"flow_prediction\"]*100\n",
    "    \n",
    "    df = pd.merge(df.reset_index(),tickers_meta[[\"ticker\",\"sector\",\"industry\"]], on=\"ticker\", how=\"left\")\n",
    "\n",
    "    df = df[df[\"industry\"]!=\"Shell Companies\"].drop(columns=[\"industry\"])\n",
    "\n",
    "    df = df.rename(columns={\"flow_prediction\":\"flowprediction\"})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "842bfe72-809f-4405-b09b-eac8475e7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import locale\n",
    "\n",
    "# Set locale to US English\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "\n",
    "\n",
    "def get_week_ending_label(reference_date=None):\n",
    "    \"\"\"\n",
    "    Returns a formatted string indicating the week ending on the last Friday relative to the reference date.\n",
    "\n",
    "    Args:\n",
    "        reference_date (datetime.date, optional): The date to reference. Defaults to today.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string like \"Week ending Friday 25th October, 2024\"\n",
    "    \"\"\"\n",
    "    if reference_date is None:\n",
    "        reference_date = datetime.date.today()\n",
    "    \n",
    "    def get_ordinal(n):\n",
    "        if 11 <= n % 100 <= 13:\n",
    "            suffix = 'th'\n",
    "        else:\n",
    "            suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(n % 10, 'th')\n",
    "        return f\"{n}{suffix}\"\n",
    "    \n",
    "    days_since_friday = (reference_date.weekday() - 4) % 7\n",
    "    last_friday = reference_date - datetime.timedelta(days=days_since_friday)\n",
    "    day_with_ordinal = get_ordinal(last_friday.day)\n",
    "    formatted_date = f\"Week ending {last_friday.strftime('%A')} {day_with_ordinal} {last_friday.strftime('%B')}, {last_friday.year}\"\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "# Usage\n",
    "formatted_week_label = get_week_ending_label()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcda6d30-a33b-422d-943b-d4520d5f801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           4,109 │               - │               - │\n",
      "│ Condition 1     │           2,979 │           1,130 │           2,979 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           4,109 │           1,130 │           2,979 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 2979 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: zNSiM\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Update result\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/zNSiM/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def create_sector_ranking(df, sort_column='sansmarket', top_n=10, select='both'):\n",
    "    def make_clickable(ticker):\n",
    "        url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "        return f'<a href=\"{url}\" target=\"_blank\">{ticker}</a>'\n",
    "    \n",
    "    # Ensure we're working with the latest date\n",
    "    latest_date = df['date'].max()\n",
    "    df_latest = df[df['date'] == latest_date]\n",
    "    \n",
    "    # Group by sector and get top N largest and smallest for each sector\n",
    "    grouped = df_latest.groupby('sector')\n",
    "    top_n_df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        if select in ['largest', 'both']:\n",
    "            top_largest = group.nlargest(top_n, sort_column)\n",
    "            top_largest = top_largest.copy()\n",
    "            top_largest['rank_type'] = 'Largest'\n",
    "            top_largest['rank'] = range(1, len(top_largest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_largest])\n",
    "        \n",
    "        if select in ['smallest', 'both']:\n",
    "            top_smallest = group.nsmallest(top_n, sort_column)\n",
    "            top_smallest = top_smallest.copy()\n",
    "            top_smallest['rank_type'] = 'Smallest'\n",
    "            top_smallest['rank'] = range(1, len(top_smallest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_smallest])\n",
    "    \n",
    "    # Format the sort_column to two decimal places\n",
    "    top_n_df[sort_column] = top_n_df[sort_column].map(\"{:.2f}\".format)\n",
    "    \n",
    "    # Make tickers clickable\n",
    "    top_n_df['ticker'] = top_n_df['ticker'].apply(make_clickable)\n",
    "    \n",
    "    # Sort the DataFrame for better organization\n",
    "    top_n_df.sort_values(['sector', 'rank_type', 'rank'], inplace=True)\n",
    "    \n",
    "    # Create a pivot table with the rank_type and rank as multi-index\n",
    "    top_n_pivot = top_n_df.pivot_table(index=['rank_type', 'rank'], \n",
    "                                      columns='sector', \n",
    "                                      values=[sort_column, 'ticker'],\n",
    "                                      aggfunc='first')\n",
    "    top_n_pivot = top_n_pivot.swaplevel(axis=1).sort_index(axis=1, level=0)\n",
    "    \n",
    "    # Prepare the data for Datawrapper format\n",
    "    output = io.StringIO()\n",
    "    \n",
    "    # Write the first row (sector names)\n",
    "    sectors = top_n_pivot.columns.get_level_values(0).unique()\n",
    "    output.write('Type,Rank,')\n",
    "    for sector in sectors:\n",
    "        output.write(f'~~~{sector}~~~,,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the second row (sans_market and ticker)\n",
    "    output.write(', ,')\n",
    "    for _ in sectors:\n",
    "        output.write(f'{sort_column},Ticker,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the data rows\n",
    "    for (rank_type, rank), row in top_n_pivot.iterrows():\n",
    "        output.write(f'{rank_type},{rank},')\n",
    "        for sector in sectors:\n",
    "            sans_market = row.get((sector, sort_column), '')\n",
    "            ticker = row.get((sector, 'ticker'), '')\n",
    "            output.write(f'{sans_market},{ticker},')\n",
    "        output.write('\\n')\n",
    "    \n",
    "    # Get the CSV string\n",
    "    csv_string = output.getvalue()\n",
    "    output.close()\n",
    "    \n",
    "    return csv_string\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# Unified configuration dictionary\n",
    "MODEL_CONFIG = {\n",
    "    'flowprediction': {\n",
    "        'model_name': \"Insider Buying Pressure\",\n",
    "        'intro': (\n",
    "            \"Model looking at predicting what stocks inside investor will be interested in buying next.\"\n",
    "            f\" {formatted_week_label}.\"\n",
    "            \" Derived from <a href='https://docs.sov.ai/realtime-datasets/equity-datasets/insider-flow-prediction'>Sov.ai™ Insiders</a> datasets.\"\n",
    "        ),\n",
    "        'start_title': {\n",
    "            True: \"Change in Insider Prediction\",\n",
    "            False: \"Level of Insider Pressure\"\n",
    "        },\n",
    "        'data_function': get_insider_flows_date,\n",
    "        'title_template': \"{start_title} - {model_name}\"\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "def generate_title_and_intro(sort_column, frequency):\n",
    "    \"\"\"\n",
    "    Generates the title, retrieves the intro, and returns the data function based on sort_column and frequency.\n",
    "    \n",
    "    Parameters:\n",
    "    - sort_column (str): The column to sort by.\n",
    "    - frequency (bool): Determines the start title based on change or level.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (title, intro, data_function)\n",
    "    \"\"\"\n",
    "    if sort_column not in MODEL_CONFIG:\n",
    "        valid_columns = ', '.join(MODEL_CONFIG.keys())\n",
    "        raise ValueError(f\"Invalid sort_column: '{sort_column}'. Available options are: {valid_columns}\")\n",
    "    \n",
    "    config = MODEL_CONFIG[sort_column]\n",
    "    \n",
    "    # Convert frequency to boolean; treat None as False\n",
    "    frequency_bool = bool(frequency)\n",
    "    \n",
    "    # Get the appropriate start_title based on frequency\n",
    "    start_title = config['start_title'].get(frequency_bool, f\"{config['model_name']} Prediction\")\n",
    "    \n",
    "    # Get current date in \"Month Year\" format\n",
    "    current_date = datetime.now()\n",
    "    month_year = current_date.strftime(\"%B %Y\")  # e.g., \"October 2024\"\n",
    "    \n",
    "    # Construct the full title using the template\n",
    "    title = config['title_template'].format(\n",
    "        start_title=start_title,\n",
    "        model_name=config['model_name'],\n",
    "        month_year=month_year\n",
    "    )\n",
    "    \n",
    "    # Get the intro text\n",
    "    intro = config['intro']\n",
    "    \n",
    "    # Get the data function\n",
    "    data_function = config['data_function']\n",
    "    \n",
    "    return title, intro, data_function\n",
    "\n",
    "\n",
    "\n",
    "from datawrapper import Datawrapper\n",
    "from IPython.display import IFrame\n",
    "from datetime import datetime\n",
    "\n",
    "def get_or_create_chart(dw, title, chart_type):\n",
    "    # Try to find an existing chart with the given title\n",
    "    charts = dw.get_charts(search=title, limit=1)\n",
    "\n",
    "    charts['total'] = 0 ##  Force to remove update function\n",
    "    \n",
    "    if charts['total'] > 0:\n",
    "        # If a chart is found, return its ID\n",
    "        print(\"Existing chart found:\")\n",
    "        return charts['list'][0]['id']\n",
    "    else:\n",
    "        # If no chart is found, create a new one\n",
    "        print(\"No existing chart found. Creating a new one.\")\n",
    "        new_chart = dw.create_chart(title=title, chart_type=chart_type)\n",
    "        print(\"New chart created:\")\n",
    "        return new_chart['id']\n",
    "\n",
    "\n",
    "\n",
    "def get_color_scheme(selection):\n",
    "    if selection == \"largest\":\n",
    "        return [\n",
    "            {\"color\": \"#f0f9e8\", \"position\": 0},\n",
    "            {\"color\": \"#b6e3bb\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#75c8c5\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#4ba8c9\", \"position\": 0.5},\n",
    "            {\"color\": \"#2989bd\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#0a6aad\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#254b8c\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"smallest\":\n",
    "        return [\n",
    "            {\"color\": \"#fff5f0\", \"position\": 0},\n",
    "            {\"color\": \"#fee0d2\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#fcbba1\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#fb6a4a\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#ef3b2c\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#cb181d\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"both\":\n",
    "        return [\n",
    "            {\"color\": \"#fff5f0\", \"position\": 0},\n",
    "            {\"color\": \"#fee0d2\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#fcbba1\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#2989bd\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#0a6aad\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#254b8c\", \"position\": 1}\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"selection must be either 'largest' or 'smallest'\")\n",
    "\n",
    "# Usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sort_table(sort_column='sansmarket', frequency=None, top_n=10, selection=\"largest\"):\n",
    "    # Function to create sector ranking CSV data\n",
    "\n",
    "    title, intro, data_func = generate_title_and_intro(sort_column, frequency)\n",
    "\n",
    "    df = data_func(frequency=frequency)\n",
    "\n",
    "    csv_data = create_sector_ranking(df, sort_column=sort_column, top_n=top_n, select=selection)\n",
    "\n",
    "    # At the beginning of your function, add:\n",
    "    current_date = datetime.now()\n",
    "    month_year = current_date.strftime(\"%B %Y\")  # This will give you \"Month Year\" format, e.g., \"October 2024\"\n",
    "\n",
    "    if frequency:\n",
    "        start_title = \"Change in Bankruptcy Prediction\"\n",
    "    else:\n",
    "        start_title = \"Level of Bankruptcy Prediction\"\n",
    "\n",
    "    \n",
    "    # Initialize Datawrapper with your access token\n",
    "    dw = Datawrapper(access_token=\"your_token\")\n",
    "    \n",
    "    chart_id = get_or_create_chart(dw, title, \"tables\")\n",
    "    print(f\"Chart ID: {chart_id}\")\n",
    "    \n",
    "    try:\n",
    "        # Update the chart with new data\n",
    "        dw.add_data(chart_id, data=csv_data)\n",
    "        print(\"Data added successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Define the updated metadata\n",
    "    updated_metadata = {\n",
    "        \"data\": {\n",
    "            \"transpose\": False,\n",
    "            \"vertical-header\": True,\n",
    "            \"horizontal-header\": True,\n",
    "            \"upload-method\": \"copy\"\n",
    "        },\n",
    "        \"visualize\": {\n",
    "            \"dark-mode-invert\": True,\n",
    "            \"perPage\": 10,  # Set this to 10 to show 10 items per page\n",
    "            \"pagination\": {\n",
    "                \"enabled\": True,\n",
    "                \"position\": \"bottom\",  # You can change this to \"top\" if you prefer\n",
    "                \"pagesPerScreen\": 10  # This will show 10 page numbers in the pagination controls\n",
    "            },\n",
    "            \"highlighted-series\": [],\n",
    "            \"highlighted-values\": [],\n",
    "            \"sharing\": {\"enabled\": False, \"url\": f\"https://www.datawrapper.de/_/{chart_id}\", \"auto\": False},\n",
    "            \"rows\": {\n",
    "                \"header\": {\"rows\": 2},\n",
    "                \"row--1\": {\n",
    "                    \"style\": {\"bold\": False, \"color\": False, \"italic\": False, \"fontSize\": 1, \"underline\": False, \"background\": False},\n",
    "                    \"format\": \"0,0.[00]\",\n",
    "                    \"moveTo\": \"top\",\n",
    "                    \"sticky\": False,\n",
    "                    \"moveRow\": False,\n",
    "                    \"stickTo\": \"top\",\n",
    "                    \"borderTop\": \"none\",\n",
    "                    \"borderBottom\": \"none\",\n",
    "                    \"borderTopColor\": \"#333333\",\n",
    "                    \"overrideFormat\": False,\n",
    "                    \"borderBottomColor\": \"#333333\"\n",
    "                }\n",
    "            },\n",
    "            \"header\": {\n",
    "                \"style\": {\"bold\": True, \"color\": False, \"italic\": False, \"fontSize\": 1.1, \"background\": False},\n",
    "                \"borderTop\": \"none\",\n",
    "                \"borderBottom\": \"2px\",\n",
    "                \"borderTopColor\": \"#333333\",\n",
    "                \"borderBottomColor\": \"#333333\"\n",
    "            },\n",
    "            \"legend\": {\n",
    "                \"size\": 170,\n",
    "                \"labels\": \"ranges\",\n",
    "                \"enabled\": False,\n",
    "                \"reverse\": False,\n",
    "                \"labelMax\": \"high\",\n",
    "                \"labelMin\": \"low\",\n",
    "                \"position\": \"above\",\n",
    "                \"interactive\": False,\n",
    "                \"labelCenter\": \"medium\",\n",
    "                \"labelFormat\": \"0,0.[00]\",\n",
    "                \"customLabels\": []\n",
    "            },\n",
    "            \"columns\": {\n",
    "                \"\": {\"align\": \"left\", \"title\": \"Rank\", \"width\": \"auto\"},\n",
    "                \"X.1\": {\"heatmap\": {\"enabled\": True}},\n",
    "                f\"*{sort_column}\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"format\": \"0.00\",\n",
    "                    \"heatmap\": {\"colors\": {\"max\": \"#ff0000\", \"min\": \"#ffcccb\"}, \"ranges\": {\"max\": 30, \"min\": -50}, \"enabled\": True}\n",
    "                },\n",
    "                \"~~~Energy~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Utilities~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Healthcare~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Technology~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Industrials~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Real Estate~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Basic Materials~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Consumer Cyclical~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Consumer Defensive~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Financial Services~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}},\n",
    "                \"~~~Communication Services~~~\": {\"format\": \"0.[00]%\", \"heatmap\": {\"enabled\": True}}\n",
    "            },\n",
    "            \"heatmap\": {\n",
    "                \"map\": {},\n",
    "                \"mode\": \"continuous\",\n",
    "                \"stops\": \"equidistant\",\n",
    "                \"palette\": 0,\n",
    "                \"rangeMax\": \"\",\n",
    "                \"rangeMin\": \"\",\n",
    "                \"stopCount\": 5,\n",
    "                \"hideValues\": False,\n",
    "                \"customStops\": [],\n",
    "                \"rangeCenter\": \"80\",\n",
    "                \"categoryOrder\": [],\n",
    "                \"interpolation\": \"deciles\",\n",
    "                \"categoryLabels\": {}\n",
    "            },\n",
    "            \"perPage\": 10,\n",
    "            \"striped\": False,\n",
    "            \"markdown\": True,\n",
    "            \"showRank\": False,\n",
    "            \"sortTable\": False,\n",
    "            \"pagination\": {\"enabled\": True, \"position\": \"bottom\"},\n",
    "            \"searchable\": False,\n",
    "            \"showHeader\": True,\n",
    "            \"compactMode\": True,\n",
    "            \"sortDirection\": \"desc\",\n",
    "            \"chart-type-set\": True,\n",
    "            \"mobileFallback\": False,\n",
    "            \"mergeEmptyCells\": True,\n",
    "            \"firstRowIsHeader\": True,\n",
    "            \"firstColumnIsSticky\": True\n",
    "        },\n",
    "        \"describe\": {\n",
    "            \"intro\": intro,\n",
    "            \"byline\": \"\",\n",
    "            \"source-name\": \"\",\n",
    "            \"source-url\": \"\",\n",
    "            # \"notes\": notes,\n",
    "            \"hide-title\": False\n",
    "        },\n",
    "        \"publish\": {\n",
    "            \"embed-width\": 600,\n",
    "            \"embed-height\": 510,\n",
    "            \"blocks\": {\n",
    "                \"logo\": {\"enabled\": False},\n",
    "                \"embed\": False,\n",
    "                \"download-pdf\": False,\n",
    "                \"download-svg\": False,\n",
    "                \"get-the-data\": True,\n",
    "                \"download-image\": False\n",
    "            },\n",
    "            \"autoDarkMode\": False,\n",
    "            \"chart-height\": 395,\n",
    "            \"force-attribution\": False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Update the chart with the new metadata\n",
    "        result = dw.update_chart(\n",
    "            chart_id,\n",
    "            metadata=updated_metadata\n",
    "        )\n",
    "        print(\"Chart updated successfully\")\n",
    "        print(f\"Update result\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating chart: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Publish the updated chart\n",
    "        publish_result = dw.publish_chart(chart_id)\n",
    "        print(\"Chart published successfully\")\n",
    "        # print(f\"Publish result: {publish_result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error publishing chart: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Retrieve and print the published chart URL\n",
    "        published_url = dw.get_chart_display_urls(chart_id)\n",
    "        print(\"Published Chart URL:\", published_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting chart URL: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract the public URL from the publish result\n",
    "    public_url = publish_result[\"data\"][\"publicUrl\"]\n",
    "    \n",
    "    # Display the chart within the notebook\n",
    "    return public_url, IFrame(src=public_url, width=1200, height=600)\n",
    "\n",
    "# Call the function\n",
    "url_levels, frame = create_sort_table(sort_column='flowprediction', frequency=None, top_n=20, selection=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85fec0e0-a94b-4f76-9b0a-6c54b605366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           4,109 │               - │               - │\n",
      "│ Condition 1     │           2,979 │           1,130 │           2,979 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           4,109 │           1,130 │           2,979 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 2979 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: m8HcL\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Update result\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/m8HcL/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "url_difference, frame = create_sort_table(sort_column='flowprediction', frequency=\"difference\", top_n=20, selection=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1a0ed21-4480-4b11-80a5-f5c134297b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 'Predict a Mockingbird - 2024-10-29' already exists. Appending new content to it.\n",
      "New content appended successfully.\n",
      "View your page here: https://www.notion.so/12e094f0f3958108a9d2e9f8577120e9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define title\n",
    "page_title = \"Predict a Mockingbird\"\n",
    "\n",
    "# Define content sections using a dictionary\n",
    "content_sections = {\n",
    "    \"section_1\": {\n",
    "        \"heading\": \"Insider Flow Pressure\",\n",
    "        \"content\": (\n",
    "            \"This looks at the level of predicted insider flows, the idea is to predict when insiders will buy stocks and to predict that in advance to ‘front-run’ them. \"\n",
    "            \"This model self-improves over time using machine learning.\"\n",
    "        ),\n",
    "        \"url\": url_levels,  # Replace with your actual URL for levels,\n",
    "        \"list\": None\n",
    "\n",
    "    },\n",
    "    \"section_2\": {\n",
    "        \"heading\": None,  # No heading for this section\n",
    "        \"content\": (\n",
    "            \"It is often better to look at the change in a prediction, it gives you a second order output that is often a better leading indicator to stock price movements.\"\n",
    "        ),\n",
    "        \"url\": url_difference,  # Replace with your actual URL for difference\n",
    "        \"list\": None\n",
    "\n",
    "    }\n",
    "    # Add more sections as needed\n",
    "}\n",
    "\n",
    "# Handle page creation or append\n",
    "handle_page_creation_or_append(page_title, DATABASE_ID, content_sections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
