{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b04c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sovai[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e5bdac8-209c-428f-8fe8-86506dc8a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up Notion credentials (hardcoded as per your request)\n",
    "NOTION_TOKEN = \"your_notion_token_here\"  # **Ensure this token is kept secure!**\n",
    "DATABASE_ID = \"your_database_id_here\"\n",
    "NOTION_VERSION = \"2022-06-28\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Notion-Version\": NOTION_VERSION,\n",
    "}\n",
    "\n",
    "def create_page(title, database_id, children):\n",
    "    \"\"\"\n",
    "    Creates a new page in the specified Notion database.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        children (list): A list of block objects to include in the page.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    page_data = {\n",
    "        \"parent\": {\"database_id\": database_id},\n",
    "        \"properties\": {\n",
    "            \"Title\": {\n",
    "                \"title\": [\n",
    "                    {\n",
    "                        \"text\": {\n",
    "                            \"content\": title\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        \"children\": children\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.notion.com/v1/pages\", headers=headers, json=page_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def find_page_by_title(database_id, title):\n",
    "    \"\"\"\n",
    "    Searches the Notion database for a page with the specified title.\n",
    "\n",
    "    Args:\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        title (str): The title to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The page object if found, else None.\n",
    "    \"\"\"\n",
    "    query_url = f\"https://api.notion.com/v1/databases/{database_id}/query\"\n",
    "    query_data = {\n",
    "        \"filter\": {\n",
    "            \"property\": \"Title\",\n",
    "            \"title\": {\n",
    "                \"equals\": title\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(query_url, headers=headers, json=query_data)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to query database:\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "        return None\n",
    "\n",
    "    results = response.json().get(\"results\")\n",
    "    if results:\n",
    "        return results[0]  # Assuming titles are unique\n",
    "    return None\n",
    "\n",
    "\n",
    "def append_to_page(page_id, children):\n",
    "    \"\"\"\n",
    "    Appends new blocks to an existing Notion page.\n",
    "\n",
    "    Args:\n",
    "        page_id (str): The ID of the page to append to.\n",
    "        children (list): A list of block objects to append.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Notion API.\n",
    "    \"\"\"\n",
    "    append_url = f\"https://api.notion.com/v1/blocks/{page_id}/children\"\n",
    "    append_data = {\n",
    "        \"children\": children\n",
    "    }\n",
    "    response = requests.patch(append_url, headers=headers, json=append_data)\n",
    "    return response\n",
    "\n",
    "\n",
    "def build_content_from_dict(content_dict):\n",
    "    \"\"\"\n",
    "    Builds Notion content blocks from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        content_dict (dict): A dictionary containing content definitions.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "\n",
    "    # Add Heading\n",
    "    if \"heading\" in content_dict and content_dict[\"heading\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"heading_2\",\n",
    "                \"heading_2\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"heading\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Add Content\n",
    "    if \"content\" in content_dict and content_dict[\"content\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"content\"]\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add List Items (Bullet Points)\n",
    "    if \"list\" in content_dict and content_dict[\"list\"]:\n",
    "        list_blocks = build_bullet_list(content_dict[\"list\"])\n",
    "        children.extend(list_blocks)\n",
    "        \n",
    "    # Add URL as a Link\n",
    "    if \"url\" in content_dict and content_dict[\"url\"]:\n",
    "        children.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"paragraph\",\n",
    "                \"paragraph\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": content_dict[\"url\"],\n",
    "                                \"link\": {\"url\": content_dict[\"url\"]}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "def build_bullet_list(items):\n",
    "    \"\"\"\n",
    "    Builds Notion bullet list blocks from a list of items.\n",
    "\n",
    "    Args:\n",
    "        items (list): A list of strings representing bullet points.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion bulleted list item block objects.\n",
    "    \"\"\"\n",
    "    bullet_blocks = []\n",
    "    for item in items:\n",
    "        bullet_blocks.append(\n",
    "            {\n",
    "                \"object\": \"block\",\n",
    "                \"type\": \"bulleted_list_item\",\n",
    "                \"bulleted_list_item\": {\n",
    "                    \"rich_text\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": {\n",
    "                                \"content\": item\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    return bullet_blocks\n",
    "\n",
    "\n",
    "def build_children_from_sections(content_sections):\n",
    "    \"\"\"\n",
    "    Iterates through the content sections dictionary and builds the children blocks.\n",
    "\n",
    "    Args:\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Notion block objects.\n",
    "    \"\"\"\n",
    "    children = []\n",
    "    for key in sorted(content_sections.keys()):\n",
    "        section = content_sections[key]\n",
    "        section_blocks = build_content_from_dict(section)\n",
    "        children.extend(section_blocks)\n",
    "    return children\n",
    "\n",
    "\n",
    "def handle_page_creation_or_append(title, database_id, content_sections):\n",
    "    \"\"\"\n",
    "    Handles the logic to either create a new page or append content to an existing page.\n",
    "\n",
    "    Args:\n",
    "        title (str): The title of the page.\n",
    "        database_id (str): The ID of the Notion database.\n",
    "        content_sections (dict): Dictionary containing all content sections.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try: \n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    full_title = f\"{title} - {current_date}\"\n",
    "\n",
    "    # Build the content blocks\n",
    "    children = build_children_from_sections(content_sections)\n",
    "\n",
    "    # Check if the page already exists\n",
    "    existing_page = find_page_by_title(database_id, full_title)\n",
    "\n",
    "    if existing_page:\n",
    "        print(f\"Page '{full_title}' already exists. Appending new content to it.\")\n",
    "        page_id = existing_page[\"id\"]\n",
    "        response = append_to_page(page_id, children)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"New content appended successfully.\")\n",
    "            # Construct the page URL manually\n",
    "            # Note: Notion page URLs follow the format https://www.notion.so/{workspace}/{page_id}\n",
    "            # However, constructing the exact URL might require additional steps.\n",
    "            # Here, we'll provide a placeholder.\n",
    "            page_url = f\"https://www.notion.so/{page_id.replace('-', '')}\"\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to append new content:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f\"Page '{full_title}' does not exist. Creating a new page with the new content.\")\n",
    "        response = create_page(full_title, database_id, children)\n",
    "        \n",
    "        # Handle the response\n",
    "        if response.status_code == 200:\n",
    "            page_url = response.json().get(\"url\", \"No URL returned\")\n",
    "            print(\"Page created successfully with the new content.\")\n",
    "            print(f\"View your page here: {page_url}\")\n",
    "        else:\n",
    "            print(\"Failed to create page:\")\n",
    "            print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d690f76c-63cd-4ca4-922c-444b9ef8dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here make space for some utility functions.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from github import Github\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def upload_file_to_github(plot_html, file_path_in_repo, commit_message=\"Add/update plot\",\n",
    "                         env_path='/Users/dereksnow/Sovai/GitHub/SovAI/.env', repo_name=\"sovai-research/sovai-research.github.io\", git_token_env_var='GIT_TOKEN'):\n",
    "    \"\"\"\n",
    "    Uploads or updates a file in the specified GitHub repository.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_html (str): The content of the file to upload (e.g., HTML string).\n",
    "    - file_path_in_repo (str): The path in the repository where the file will be uploaded (e.g., 'plots/risks/turing_risk_plot.html').\n",
    "    - commit_message (str): The commit message. Defaults to \"Add/update plot\".\n",
    "    - env_path (str, optional): The path to the .env file. If None, load_dotenv() will search automatically.\n",
    "    - repo_name (str, optional): The full name of the repository (e.g., \"owner/repo\"). If None, read from environment variable 'GIT_REPO_NAME'.\n",
    "    - git_token_env_var (str, optional): The name of the environment variable that holds the GitHub token. Defaults to 'GIT_TOKEN'.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the GitHub token or repository name is not provided.\n",
    "    - Exception: For other unexpected errors during the upload/update process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load environment variables\n",
    "    if env_path:\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "    else:\n",
    "        load_dotenv()  # Automatically load from .env in current or parent directories\n",
    "\n",
    "    # Retrieve GitHub token from environment variables\n",
    "    GIT_TOKEN = os.getenv(git_token_env_var)\n",
    "    if not GIT_TOKEN:\n",
    "        raise ValueError(f\"{git_token_env_var} not found in environment variables. Please set it in the .env file or environment.\")\n",
    "\n",
    "    # Initialize GitHub client\n",
    "    g = Github(GIT_TOKEN)\n",
    "\n",
    "    # Retrieve repository name\n",
    "    if not repo_name:\n",
    "        repo_name = os.getenv('GIT_REPO_NAME')\n",
    "        if not repo_name:\n",
    "            raise ValueError(\"Repository name not specified and 'GIT_REPO_NAME' not found in environment variables.\")\n",
    "\n",
    "    # Initialize repository\n",
    "    try:\n",
    "        repo = g.get_repo(repo_name)\n",
    "        print(f\"Successfully connected to repository: {repo.full_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing repository '{repo_name}': {e}\")\n",
    "        raise e\n",
    "\n",
    "    # Upload or update the file\n",
    "    try:\n",
    "        # Attempt to get the existing file\n",
    "        contents = repo.get_contents(file_path_in_repo)\n",
    "        # If the file exists, update it\n",
    "        repo.update_file(contents.path, commit_message, plot_html, contents.sha)\n",
    "        print(f\"File '{file_path_in_repo}' updated successfully.\")\n",
    "    except Exception as e:\n",
    "        if \"404\" in str(e):\n",
    "            # If the file does not exist, create it\n",
    "            repo.create_file(file_path_in_repo, commit_message, plot_html)\n",
    "            print(f\"File '{file_path_in_repo}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31a8b81-63b4-49c8-9e61-98402e4ca8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\") \n",
    "\n",
    "tickers_meta = pd.read_parquet(\"data/tickers.parq\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_filter is your DataFrame\n",
    "\n",
    "def acquisition_filter():\n",
    "\n",
    "    df_filter = pd.read_parquet(\"https://storage.googleapis.com/sovai-public/concats/filters/latest.parquet\")\n",
    "    # Calculate the percentage difference between current price and moving averages\n",
    "    df_filter['perc_diff_50d_ma'] = np.abs((df_filter['current_price'] - df_filter['50_day_ma']) / df_filter['50_day_ma']) * 100\n",
    "    df_filter['perc_diff_200d_ma'] = np.abs((df_filter['current_price'] - df_filter['200_day_ma']) / df_filter['200_day_ma']) * 100\n",
    "    \n",
    "    # Define thresholds based on the data distribution\n",
    "    volatility_threshold = df_filter['volatility_30d'].quantile(0.05)  # Lower 25% volatility\n",
    "    volume_threshold = 10000  # Minimum average volume\n",
    "    \n",
    "    # Filter companies based on the criteria\n",
    "    stable_companies = df_filter[\n",
    "        (df_filter['volatility_30d'] <= volatility_threshold) &\n",
    "        (df_filter['weekly_return'].abs() <= 1) &\n",
    "        (df_filter['monthly_return'].abs() <= 2) &\n",
    "        (df_filter['perc_diff_50d_ma'] <= 2) &\n",
    "        # (df_filter['perc_diff_200d_ma'] <= 2) &\n",
    "        (df_filter['avg_volume_30d'] >= volume_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Select relevant columns for analysis\n",
    "    result = stable_companies[['current_price', '50_day_ma', '200_day_ma', 'volatility_30d', 'weekly_return', 'monthly_return', 'avg_volume_30d']]\n",
    "\n",
    "    tickers  = list(result.index.values)\n",
    "    return tickers\n",
    "    \n",
    "remove_tickers = acquisition_filter()\n",
    "\n",
    "# df = sov.data(\"institutional/flow_prediction\", frequency=\"difference\", purge_cache=True)\n",
    "\n",
    "# df = sov.data(\"institutional/flow_prediction\", frequency=\"difference\")\n",
    "# df.filter([\"market_cap>100\"])\n",
    "\n",
    "def get_last_diff(df):\n",
    "    # Sort by date and take last 2 rows per ticker\n",
    "    last_2_rows = df.reset_index().groupby('ticker').tail(2)\n",
    "    \n",
    "    # Calculate difference between last two values\n",
    "    result = last_2_rows.groupby('ticker').agg({\n",
    "        'date': 'last',\n",
    "        'flow_prediction': lambda x: x.iloc[-1] - x.iloc[-2]\n",
    "    }).reset_index()\n",
    "    \n",
    "    result.columns = ['ticker', 'latest_date', 'prediction_difference']\n",
    "    return result\n",
    "    \n",
    "def get_institutional_flows_date(frequency=\"difference\"):\n",
    "\n",
    "    df = sov.data(\"institutional/flow_prediction\", frequency=frequency)\n",
    "\n",
    "    if frequency ==\"difference\":\n",
    "        df = df.set_index([\"ticker\",\"date\"])\n",
    "    \n",
    "    df = df.filter([\"market_cap>100\"])\n",
    "\n",
    "    df[[\"flow_prediction\"]] = df[[\"flow_prediction\"]]*100\n",
    "    \n",
    "    df = pd.merge(df[[\"flow_prediction\"]].reset_index(),tickers_meta[[\"ticker\",\"sector\",\"industry\"]], on=\"ticker\", how=\"left\")\n",
    "\n",
    "    df = df[df[\"industry\"]!=\"Shell Companies\"].drop(columns=[\"industry\"])\n",
    "\n",
    "    df = df.rename(columns={\"flow_prediction\":\"instituteflow\"})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c32972b-c4e0-4904-9bdb-c71f3f4de873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1: market_cap>100 (Standard filter)\n",
      "\n",
      "Filtering Results:\n",
      "┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐\n",
      "│ Step            │   Total Tickers │         Removed │            Left │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Initial         │           4,979 │               - │               - │\n",
      "│ Condition 1     │           2,964 │           2,015 │           2,964 │\n",
      "┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼\n",
      "│ Final           │           4,979 │           2,015 │           2,964 │\n",
      "└─────────────────┴─────────────────┴─────────────────┴─────────────────┘\n",
      "Warning: Only 2964 out of 3758 filtered companies found in df_multi.\n",
      "No existing chart found. Creating a new one.\n",
      "New chart created:\n",
      "Chart ID: ovG0H\n",
      "Data added successfully\n",
      "Chart updated successfully\n",
      "Chart published successfully\n",
      "Published Chart URL: [{'id': 'standalone', 'url': 'https://www.datawrapper.de/_/ovG0H/', 'name': 'For sharing'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def create_sector_ranking(df, sort_column='sansmarket', top_n=10, select='both'):\n",
    "    def make_clickable(ticker):\n",
    "        url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "        return f'<a href=\"{url}\" target=\"_blank\">{ticker}</a>'\n",
    "    \n",
    "    # Ensure we're working with the latest date\n",
    "    latest_date = df['date'].max()\n",
    "    df_latest = df[df['date'] == latest_date]\n",
    "    \n",
    "    # Group by sector and get top N largest and smallest for each sector\n",
    "    grouped = df_latest.groupby('sector')\n",
    "    top_n_df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        if select in ['largest', 'both']:\n",
    "            top_largest = group.nlargest(top_n, sort_column)\n",
    "            top_largest = top_largest.copy()\n",
    "            top_largest['rank_type'] = 'Largest'\n",
    "            top_largest['rank'] = range(1, len(top_largest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_largest])\n",
    "        \n",
    "        if select in ['smallest', 'both']:\n",
    "            top_smallest = group.nsmallest(top_n, sort_column)\n",
    "            top_smallest = top_smallest.copy()\n",
    "            top_smallest['rank_type'] = 'Smallest'\n",
    "            top_smallest['rank'] = range(1, len(top_smallest) + 1)\n",
    "            top_n_df = pd.concat([top_n_df, top_smallest])\n",
    "    \n",
    "    # Format the sort_column to two decimal places\n",
    "    top_n_df[sort_column] = top_n_df[sort_column].map(\"{:.2f}\".format)\n",
    "    \n",
    "    # Make tickers clickable\n",
    "    top_n_df['ticker'] = top_n_df['ticker'].apply(make_clickable)\n",
    "    \n",
    "    # Sort the DataFrame for better organization\n",
    "    top_n_df.sort_values(['sector', 'rank_type', 'rank'], inplace=True)\n",
    "    \n",
    "    # Create a pivot table with the rank_type and rank as multi-index\n",
    "    top_n_pivot = top_n_df.pivot_table(index=['rank_type', 'rank'], \n",
    "                                      columns='sector', \n",
    "                                      values=[sort_column, 'ticker'],\n",
    "                                      aggfunc='first')\n",
    "    top_n_pivot = top_n_pivot.swaplevel(axis=1).sort_index(axis=1, level=0)\n",
    "    \n",
    "    # Prepare the data for Datawrapper format\n",
    "    output = io.StringIO()\n",
    "    \n",
    "    # Write the first row (sector names)\n",
    "    sectors = top_n_pivot.columns.get_level_values(0).unique()\n",
    "    output.write('Type,Rank,')\n",
    "    for sector in sectors:\n",
    "        output.write(f'~~~{sector}~~~,,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the second row (sans_market and ticker)\n",
    "    output.write(', ,')\n",
    "    for _ in sectors:\n",
    "        output.write(f'{sort_column},Ticker,')\n",
    "    output.write('\\n')\n",
    "    \n",
    "    # Write the data rows\n",
    "    for (rank_type, rank), row in top_n_pivot.iterrows():\n",
    "        output.write(f'{rank_type},{rank},')\n",
    "        for sector in sectors:\n",
    "            sans_market = row.get((sector, sort_column), '')\n",
    "            ticker = row.get((sector, 'ticker'), '')\n",
    "            output.write(f'{sans_market},{ticker},')\n",
    "        output.write('\\n')\n",
    "    \n",
    "    # Get the CSV string\n",
    "    csv_string = output.getvalue()\n",
    "    output.close()\n",
    "    \n",
    "    return csv_string\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# Unified configuration dictionary\n",
    "MODEL_CONFIG = {\n",
    "    'instituteflow': {\n",
    "        'model_name': \"Insitutional Buying Pressure\",\n",
    "        'intro': (\n",
    "            \"Model looking at predicting what stocks institutional investors will be interested in, \"\n",
    "            \"buying next | \"\n",
    "            '<a href=\"https://sov.ai\">Sov.ai™</a>'\n",
    "        ),\n",
    "        'start_title': {\n",
    "            True: \"Change in Insitutional Prediction\",\n",
    "            False: \"Level of Insittutional Pressure\"\n",
    "        },\n",
    "        'data_function': get_institutional_flows_date,\n",
    "        'title_template': \"{start_title} - {model_name} ({month_year})\"\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "def generate_title_and_intro(sort_column, frequency):\n",
    "    \"\"\"\n",
    "    Generates the title, retrieves the intro, and returns the data function based on sort_column and frequency.\n",
    "    \n",
    "    Parameters:\n",
    "    - sort_column (str): The column to sort by.\n",
    "    - frequency (bool): Determines the start title based on change or level.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (title, intro, data_function)\n",
    "    \"\"\"\n",
    "    if sort_column not in MODEL_CONFIG:\n",
    "        valid_columns = ', '.join(MODEL_CONFIG.keys())\n",
    "        raise ValueError(f\"Invalid sort_column: '{sort_column}'. Available options are: {valid_columns}\")\n",
    "    \n",
    "    config = MODEL_CONFIG[sort_column]\n",
    "    \n",
    "    # Convert frequency to boolean; treat None as False\n",
    "    frequency_bool = bool(frequency)\n",
    "    \n",
    "    # Get the appropriate start_title based on frequency\n",
    "    start_title = config['start_title'].get(frequency_bool, f\"{config['model_name']} Prediction\")\n",
    "    \n",
    "    # Get current date in \"Month Year\" format\n",
    "    current_date = datetime.now()\n",
    "    month_year = current_date.strftime(\"%B %Y\")  # e.g., \"October 2024\"\n",
    "    \n",
    "    # Construct the full title using the template\n",
    "    title = config['title_template'].format(\n",
    "        start_title=start_title,\n",
    "        model_name=config['model_name'],\n",
    "        month_year=month_year\n",
    "    )\n",
    "    \n",
    "    # Get the intro text\n",
    "    intro = config['intro']\n",
    "    \n",
    "    # Get the data function\n",
    "    data_function = config['data_function']\n",
    "    \n",
    "    return title, intro, data_function\n",
    "\n",
    "\n",
    "\n",
    "from datawrapper import Datawrapper\n",
    "from IPython.display import IFrame\n",
    "from datetime import datetime\n",
    "\n",
    "def get_or_create_chart(dw, title, chart_type):\n",
    "    # Try to find an existing chart with the given title\n",
    "    charts = dw.get_charts(search=title, limit=1)\n",
    "\n",
    "    charts['total'] = 0 ##  Force to remove update function\n",
    "    \n",
    "    if charts['total'] > 0:\n",
    "        # If a chart is found, return its ID\n",
    "        print(\"Existing chart found:\")\n",
    "        return charts['list'][0]['id']\n",
    "    else:\n",
    "        # If no chart is found, create a new one\n",
    "        print(\"No existing chart found. Creating a new one.\")\n",
    "        new_chart = dw.create_chart(title=title, chart_type=chart_type)\n",
    "        print(\"New chart created:\")\n",
    "        return new_chart['id']\n",
    "\n",
    "\n",
    "\n",
    "def get_color_scheme(selection):\n",
    "    if selection == \"largest\":\n",
    "        return [\n",
    "            {\"color\": \"#f0f9e8\", \"position\": 0},\n",
    "            {\"color\": \"#b6e3bb\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#75c8c5\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#4ba8c9\", \"position\": 0.5},\n",
    "            {\"color\": \"#2989bd\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#0a6aad\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#254b8c\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"smallest\":\n",
    "        return [\n",
    "            {\"color\": \"#fff5f0\", \"position\": 0},\n",
    "            {\"color\": \"#fee0d2\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#fcbba1\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#fb6a4a\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#ef3b2c\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#cb181d\", \"position\": 1}\n",
    "        ]\n",
    "    elif selection == \"both\":\n",
    "        return [\n",
    "            {\"color\": \"#f0f9e8\", \"position\": 0},\n",
    "            {\"color\": \"#b6e3bb\", \"position\": 0.16666666666666666},\n",
    "            {\"color\": \"#75c8c5\", \"position\": 0.3333333333333333},\n",
    "            {\"color\": \"#fc9272\", \"position\": 0.5},\n",
    "            {\"color\": \"#fb6a4a\", \"position\": 0.6666666666666666},\n",
    "            {\"color\": \"#ef3b2c\", \"position\": 0.8333333333333334},\n",
    "            {\"color\": \"#cb181d\", \"position\": 1}\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"selection must be either 'largest' or 'smallest'\")\n",
    "\n",
    "# Usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sort_table(sort_column='slopebreak', frequency=None, top_n=10, selection=\"largest\"):\n",
    "    \"\"\"\n",
    "    Creates and updates a Datawrapper table with appropriate heatmap settings.\n",
    "    \n",
    "    Parameters:\n",
    "    - sort_column (str): The column to sort by ('slopebreak' or 'predictbreak').\n",
    "    - frequency (bool or None): Determines if it's a change or level metric.\n",
    "    - top_n (int): Number of top entries per sector.\n",
    "    - selection (str): 'largest', 'smallest', or 'both'.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (public_url, IFrame object)\n",
    "    \"\"\"\n",
    "    # Generate title, intro, and data function based on sort_column and frequency\n",
    "    title, intro, data_func = generate_title_and_intro(sort_column, frequency)\n",
    "\n",
    "    # Fetch and process the data\n",
    "    df = data_func(frequency=frequency)\n",
    "    csv_data = create_sector_ranking(df, sort_column=sort_column, top_n=top_n, select=selection)\n",
    "\n",
    "    # Initialize Datawrapper with your access token\n",
    "    dw = Datawrapper(access_token=\"your_token\")\n",
    "\n",
    "    # Create or get existing chart\n",
    "    chart_id = get_or_create_chart(dw, title, \"tables\")\n",
    "    print(f\"Chart ID: {chart_id}\")\n",
    "\n",
    "    try:\n",
    "        # Update the chart with new data\n",
    "        dw.add_data(chart_id, data=csv_data)\n",
    "        print(\"Data added successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Define sectors based on your data\n",
    "    sectors = ['Energy', 'Utilities', 'Healthcare', 'Technology', 'Industrials', \n",
    "               'Real Estate', 'Basic Materials', 'Consumer Cyclical', \n",
    "               'Consumer Defensive', 'Financial Services', 'Communication Services']\n",
    "\n",
    "    # Dynamically generate heatmap color palette\n",
    "    # Adjust the colors and positions as per your requirements\n",
    "    heatmap_colors = [\n",
    "       {\"color\": \"#67000d\", \"position\": -0.6},    # Deepest red (most negative)\n",
    "       {\"color\": \"#99000d\", \"position\": -0.45},   # Very dark red  \n",
    "       {\"color\": \"#cb181d\", \"position\": -0.3},    # Dark red\n",
    "       {\"color\": \"#ef3b2c\", \"position\": -0.15},   # Medium red\n",
    "       {\"color\": \"#fb6a4a\", \"position\": 0},       # Light red\n",
    "       {\"color\": \"#67c1cd\", \"position\": 0.15},    # Very light blue\n",
    "       {\"color\": \"#2989bd\", \"position\": 0.3},     # Light blue\n",
    "       {\"color\": \"#0a6aad\", \"position\": 0.45},    # Medium blue \n",
    "       {\"color\": \"#254b8c\", \"position\": 0.6}      # Deep blue (most positive)\n",
    "    ]\n",
    "\n",
    "    # Determine appropriate heatmap ranges based on data\n",
    "    sort_min = df[sort_column].min()\n",
    "    sort_max = df[sort_column].max()\n",
    "\n",
    "    # Prepare the 'columns' configuration\n",
    "    columns_config = {\n",
    "        \"\": {\"align\": \"left\", \"title\": \"Rank\", \"width\": \"auto\"},\n",
    "        \"Type\": {\"align\": \"left\", \"title\": \"Type\", \"width\": \"auto\"},\n",
    "    }\n",
    "\n",
    "    for sector in sectors:\n",
    "        columns_config[f\"~~~{sector}~~~\"] = {\n",
    "            \"format\": \"0.[00]%\",  # Adjust format as needed\n",
    "            \"heatmap\": {\n",
    "                \"enabled\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Define the updated_metadata with detailed heatmap settings\n",
    "    updated_metadata = {\n",
    "        \"data\": {\n",
    "            \"transpose\": False,\n",
    "            \"vertical-header\": True,\n",
    "            \"horizontal-header\": True,\n",
    "            \"upload-method\": \"copy\"\n",
    "        },\n",
    "        \"visualize\": {\n",
    "            \"dark-mode-invert\": True,\n",
    "            \"perPage\": 10,  # Items per page\n",
    "            \"pagination\": {\n",
    "                \"enabled\": True,\n",
    "                \"position\": \"bottom\",\n",
    "                \"pagesPerScreen\": 10\n",
    "            },\n",
    "            \"highlighted-series\": [],\n",
    "            \"highlighted-values\": [],\n",
    "            \"sharing\": {\n",
    "                \"enabled\": False,\n",
    "                \"url\": f\"https://www.datawrapper.de/_/{chart_id}\",\n",
    "                \"auto\": False\n",
    "            },\n",
    "            \"rows\": {\n",
    "                \"header\": {\"rows\": 2},\n",
    "                \"row--1\": {\n",
    "                    \"style\": {\n",
    "                        \"bold\": False,\n",
    "                        \"color\": False,\n",
    "                        \"italic\": False,\n",
    "                        \"fontSize\": 1,\n",
    "                        \"underline\": False,\n",
    "                        \"background\": False\n",
    "                    },\n",
    "                    \"format\": \"0,0.[00]\",\n",
    "                    \"moveTo\": \"top\",\n",
    "                    \"sticky\": False,\n",
    "                    \"moveRow\": False,\n",
    "                    \"stickTo\": \"top\",\n",
    "                    \"borderTop\": \"none\",\n",
    "                    \"borderBottom\": \"none\",\n",
    "                    \"borderTopColor\": \"#333333\",\n",
    "                    \"overrideFormat\": False,\n",
    "                    \"borderBottomColor\": \"#333333\"\n",
    "                }\n",
    "            },\n",
    "            \"header\": {\n",
    "                \"style\": {\n",
    "                    \"bold\": True,\n",
    "                    \"color\": False,\n",
    "                    \"italic\": False,\n",
    "                    \"fontSize\": 1.1,\n",
    "                    \"background\": False\n",
    "                },\n",
    "                \"borderTop\": \"none\",\n",
    "                \"borderBottom\": \"2px\",\n",
    "                \"borderTopColor\": \"#333333\",\n",
    "                \"borderBottomColor\": \"#333333\"\n",
    "            },\n",
    "            \"legend\": {\n",
    "                \"size\": 170,\n",
    "                \"labels\": \"ranges\",\n",
    "                \"enabled\": False,\n",
    "                \"reverse\": False,\n",
    "                \"labelMax\": \"high\",\n",
    "                \"labelMin\": \"low\",\n",
    "                \"position\": \"above\",\n",
    "                \"interactive\": False,\n",
    "                \"labelCenter\": \"medium\",\n",
    "                \"labelFormat\": \"0,0.[00]\",\n",
    "                \"customLabels\": []\n",
    "            },\n",
    "            \"columns\": columns_config,\n",
    "            \"heatmap\": {\n",
    "                \"map\": {},\n",
    "                \"mode\": \"continuous\",\n",
    "                \"stops\": \"equidistant\",\n",
    "                \"palette\": 0,\n",
    "                \"rangeMax\": \"\",  # Let Datawrapper auto-calculate or set manually\n",
    "                \"rangeMin\": \"\",\n",
    "                \"stopCount\": 5,\n",
    "                \"hideValues\": False,\n",
    "                \"customStops\": [],\n",
    "                \"rangeCenter\": \"30\",  # Adjust based on your data\n",
    "                \"categoryOrder\": [],\n",
    "                \"categoryLabels\": {},\n",
    "                \"colors\": heatmap_colors  # Custom color palette\n",
    "            },\n",
    "            \"perPage\": 10,\n",
    "            \"striped\": False,\n",
    "            \"markdown\": True,\n",
    "            \"showRank\": False,\n",
    "            \"sortTable\": False,\n",
    "            \"pagination\": {\"enabled\": True, \"position\": \"bottom\"},\n",
    "            \"searchable\": False,\n",
    "            \"showHeader\": True,\n",
    "            \"compactMode\": True,\n",
    "            \"sortDirection\": \"desc\",\n",
    "            \"chart-type-set\": True,\n",
    "            \"mobileFallback\": False,\n",
    "            \"mergeEmptyCells\": True,\n",
    "            \"firstRowIsHeader\": True,\n",
    "            \"firstColumnIsSticky\": True\n",
    "        },\n",
    "        \"describe\": {\n",
    "            \"intro\": intro,\n",
    "            \"byline\": \"\",\n",
    "            \"source-name\": \"\",\n",
    "            \"source-url\": \"\",\n",
    "            \"hide-title\": False\n",
    "        },\n",
    "        \"publish\": {\n",
    "            \"embed-width\": 600,\n",
    "            \"embed-height\": 510,\n",
    "            \"blocks\": {\n",
    "                \"logo\": {\"enabled\": False},\n",
    "                \"embed\": False,\n",
    "                \"download-pdf\": False,\n",
    "                \"download-svg\": False,\n",
    "                \"get-the-data\": True,\n",
    "                \"download-image\": False\n",
    "            },\n",
    "            \"autoDarkMode\": False,\n",
    "            \"chart-height\": 395,\n",
    "            \"force-attribution\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # # Optionally, adjust 'rangeCenter' based on sort_column\n",
    "    # if sort_column == 'slopebreak':\n",
    "    # updated_metadata['visualize']['heatmap']['rangeCenter'] = \"0\"  # Example adjustment\n",
    "\n",
    "    # Add dynamic range calculation\n",
    "    updated_metadata['visualize']['heatmap'].update({\n",
    "        'rangeMin': -60,\n",
    "        'rangeMax': 60,\n",
    "        'rangeCenter': 0\n",
    "    })\n",
    "    # elif sort_column == 'predictbreak':\n",
    "    #     updated_metadata['visualize']['heatmap']['rangeCenter'] = \"30\"  # Example adjustment\n",
    "\n",
    "    # Update the chart with the new metadata\n",
    "    try:\n",
    "        result = dw.update_chart(chart_id, metadata=updated_metadata)\n",
    "        print(\"Chart updated successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating chart: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Publish the updated chart\n",
    "    try:\n",
    "        publish_result = dw.publish_chart(chart_id)\n",
    "        print(\"Chart published successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error publishing chart: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve and print the published chart URL\n",
    "    try:\n",
    "        published_url = dw.get_chart_display_urls(chart_id)\n",
    "        print(\"Published Chart URL:\", published_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting chart URL: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the public URL from the publish result\n",
    "    public_url = publish_result[\"data\"][\"publicUrl\"]\n",
    "\n",
    "    # Display the chart within the notebook\n",
    "    return public_url, IFrame(src=public_url, width=1200, height=600)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "# url_levels, frame  = create_sort_table(sort_column='slopebreak', frequency=None, top_n=40, selection=\"both\")\n",
    "# Call the function\n",
    "url_instutte, frame = create_sort_table(sort_column='instituteflow', frequency=\"difference\", top_n=20, selection=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a1506e-cd2d-400e-9bda-6305fe49da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 'Predict a Mockingbird - 2024-10-30' already exists. Appending new content to it.\n",
      "New content appended successfully.\n",
      "View your page here: https://www.notion.so/12f094f0f39581b4b996e912a2f7a7f4\n"
     ]
    }
   ],
   "source": [
    "# Define title\n",
    "page_title = \"Predict a Monthly Bird\"\n",
    "\n",
    "# Define content sections using the content_sections dictionary\n",
    "content_sections = {\n",
    "    \"section_1\": {\n",
    "        \"heading\": \"Change in Institutional Flow\",\n",
    "        \"content\": (\n",
    "            \"Using sophisticated machine learning models we predict future institutional pressure\"\n",
    "            \". This model specifically is looking at identifying changes in those predictions.\"\n",
    "            \n",
    "        ),\n",
    "        \"url\": url_instutte,\n",
    "        \"list\": None\n",
    "    },\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Handle page creation or append\n",
    "handle_page_creation_or_append(page_title, DATABASE_ID, content_sections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
