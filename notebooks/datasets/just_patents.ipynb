{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sovai[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a354c9-e5d1-4852-a001-e778fd06ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04921150-7552-4d39-b203-5d09228b423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_meta = pd.read_parquet(\"data/tickers.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ab9224c-c19a-4459-b6d3-58a0218f9ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>permaticker</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>isdelisted</th>\n",
       "      <th>category</th>\n",
       "      <th>cusips</th>\n",
       "      <th>siccode</th>\n",
       "      <th>sicsector</th>\n",
       "      <th>sicindustry</th>\n",
       "      <th>famasector</th>\n",
       "      <th>famaindustry</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>scalemarketcap</th>\n",
       "      <th>scalerevenue</th>\n",
       "      <th>relatedtickers</th>\n",
       "      <th>currency</th>\n",
       "      <th>location</th>\n",
       "      <th>lastupdated</th>\n",
       "      <th>firstadded</th>\n",
       "      <th>firstpricedate</th>\n",
       "      <th>lastpricedate</th>\n",
       "      <th>firstquarter</th>\n",
       "      <th>lastquarter</th>\n",
       "      <th>secfilings</th>\n",
       "      <th>companysite</th>\n",
       "      <th>active</th>\n",
       "      <th>foreign</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16616</th>\n",
       "      <td>SF1</td>\n",
       "      <td>198012</td>\n",
       "      <td>WFM</td>\n",
       "      <td>WHOLE FOODS MARKET INC</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>Y</td>\n",
       "      <td>Domestic Common Stock</td>\n",
       "      <td>966837106</td>\n",
       "      <td>5411.000</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>Retail-Grocery Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>Grocery Stores</td>\n",
       "      <td>large</td>\n",
       "      <td>large</td>\n",
       "      <td>WFMI</td>\n",
       "      <td>USD</td>\n",
       "      <td>Texas; U.S.A</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>1992-01-23</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>1996-12-31</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>https://www.sec.gov/cgi-bin/browse-edgar?actio...</td>\n",
       "      <td>None</td>\n",
       "      <td>Active</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Common Stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      table  permaticker ticker                    name exchange isdelisted  \\\n",
       "16616   SF1       198012    WFM  WHOLE FOODS MARKET INC   NASDAQ          Y   \n",
       "\n",
       "                    category     cusips  siccode     sicsector  \\\n",
       "16616  Domestic Common Stock  966837106 5411.000  Retail Trade   \n",
       "\n",
       "                 sicindustry  famasector famaindustry              sector  \\\n",
       "16616  Retail-Grocery Stores         NaN       Retail  Consumer Defensive   \n",
       "\n",
       "             industry scalemarketcap scalerevenue relatedtickers currency  \\\n",
       "16616  Grocery Stores          large        large           WFMI      USD   \n",
       "\n",
       "           location lastupdated  firstadded firstpricedate lastpricedate  \\\n",
       "16616  Texas; U.S.A  2019-05-07  2015-02-19     1992-01-23    2017-08-28   \n",
       "\n",
       "      firstquarter lastquarter  \\\n",
       "16616   1996-12-31  2017-06-30   \n",
       "\n",
       "                                              secfilings companysite  active  \\\n",
       "16616  https://www.sec.gov/cgi-bin/browse-edgar?actio...        None  Active   \n",
       "\n",
       "        foreign         class  \n",
       "16616  Domestic  Common Stock  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_meta[tickers_meta[\"ticker\"]==\"WFM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4693bdd-83a0-42a8-bb2e-df50400e4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code = pd.read_parquet(\"gs://sovai-public/sovai-master/output/df_codes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64783030-1ee3-4a2e-bdbf-b8a7159a7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4f2aa1-801e-4072-bb71-fbad035a8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_institute = sov.data(\"institutional/trading\", start_date=\"2004-04-30\", tickers=[\"AMZN\", \"DDD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70387109-8f7f-4be8-b1f3-37638b7e83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios = sov.data(\"ratios/normal\", tickers=[\"WFM\"]); df_ratios.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1f89ec-c842-408e-988b-6eb418e5dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "from pyarrow.fs import S3FileSystem\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sovai.tools.authentication import authentication\n",
    "\n",
    "# Try to import CustomDataFrame, use regular DataFrame if not available\n",
    "try:\n",
    "    from sovai.extensions.pandas_extensions import CustomDataFrame\n",
    "    HAS_CUSTOM_DATAFRAME = True\n",
    "except ImportError:\n",
    "    HAS_CUSTOM_DATAFRAME = False\n",
    "    CustomDataFrame = pd.DataFrame  # Fallback to regular DataFrame\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=2)\n",
    "def get_cached_s3_filesystem(storage_provider):\n",
    "    return authentication.get_s3_filesystem_pickle(storage_provider, verbose=True)\n",
    "\n",
    "@lru_cache(maxsize=2)\n",
    "def get_cached_s3fs_filesystem(storage_provider):\n",
    "    return authentication.get_s3fs_filesystem_json(storage_provider, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cdb7db-d76c-45a6-a72a-caf1cfc792d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import s3fs\n",
    "import logging\n",
    "import datetime\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from pyarrow.fs import S3FileSystem\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration and Credential Management\n",
    "# -------------------------------\n",
    "\n",
    "# -------------------------------\n",
    "# Logging Configuration\n",
    "# -------------------------------\n",
    "\n",
    "# Configure logging to output to both console and a log file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"data_operations.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "def construct_s3_path(type_name, provider, partition_type, ticker=None, publish_date=None, year=None, all_dates_after=False):\n",
    "    \"\"\"\n",
    "    Construct the S3 path based on the partitioning scheme.\n",
    "\n",
    "    Parameters:\n",
    "    - type_name (str): Type of data (e.g., 'applications')\n",
    "    - provider (str): 'wasabi' or 'digitalocean'\n",
    "    - partition_type (str): 'date' or 'ticker'\n",
    "    - ticker (str, optional): Ticker symbol\n",
    "    - publish_date (str, optional): Publish date in 'YYYY-MM-DD' format\n",
    "    - year (int, optional): Year extracted from publish_date\n",
    "    - all_dates_after (bool, optional): If True, scan all date partitions after a certain date\n",
    "\n",
    "    Returns:\n",
    "    - str: Constructed S3 path\n",
    "    \"\"\"\n",
    "    if provider==\"digitalocean\":\n",
    "        bucket =\"sovai/sovai-patents-export\"\n",
    "    else:\n",
    "        bucket = \"sovai-patents-export\"\n",
    "        \n",
    "\n",
    "    if partition_type == \"date\":\n",
    "        if all_dates_after:\n",
    "            # Return the parent directory to scan all date partitions\n",
    "            path = f\"{type_name}/date/\"\n",
    "        else:\n",
    "            if not publish_date:\n",
    "                raise ValueError(\"publish_date must be provided for date partitioning.\")\n",
    "            path = f\"{type_name}/date/date_partitioned={publish_date}/\"\n",
    "    elif partition_type == \"ticker\":\n",
    "        if not ticker or not year:\n",
    "            raise ValueError(\"Both ticker and year must be provided for ticker partitioning.\")\n",
    "        path = f\"{type_name}/ticker/ticker_partitioned={ticker}/year={year}/\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid partition_type. Choose 'date' or 'ticker'.\")\n",
    "\n",
    "    return f\"{bucket}/{path}\"\n",
    "\n",
    "\n",
    "def list_date_partitions(provider, type_name):\n",
    "    s3_path = construct_s3_path(type_name, provider, partition_type=\"date\", all_dates_after=True)\n",
    "    fs = get_cached_s3fs_filesystem(provider)\n",
    "    try:\n",
    "        partitions = fs.ls(s3_path)\n",
    "        dates = []\n",
    "        for partition in partitions:\n",
    "            basename = os.path.basename(partition.rstrip('/'))\n",
    "            if basename.startswith('date_partitioned='):\n",
    "                date_str = basename.split('=')[1]\n",
    "                try:\n",
    "                    date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "                    dates.append((date_obj, partition))\n",
    "                except ValueError:\n",
    "                    logger.warning(f\"Unable to parse date from partition {partition}\")\n",
    "        return dates\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing date partitions in {s3_path} ({provider}): {e}\")\n",
    "        return []\n",
    "\n",
    "def load_parquet_from_s3(s3_path, provider, columns=None, start_date=None):\n",
    "    \"\"\"\n",
    "    Load a Parquet file from S3 into a pandas DataFrame with optional date filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - s3_path (str): S3 path to the Parquet file or directory\n",
    "    - provider (str): 'wasabi' or 'digitalocean'\n",
    "    - columns (list, optional): List of columns to select\n",
    "    - start_date (str, optional): Minimum date in 'YYYY-MM-DD' format to filter the data\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: Loaded DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    fs = get_cached_s3_filesystem(provider)\n",
    "    \n",
    "    try:\n",
    "        dataset = ds.dataset(s3_path, filesystem=fs, format='parquet')\n",
    "\n",
    "        if start_date:\n",
    "            # Convert start_date string to pyarrow date32 scalar\n",
    "            min_date_pa = pa.scalar(pd.to_datetime(start_date).date(), type=pa.date32())\n",
    "            # Use ds.field to construct the filter expression\n",
    "            filter_expr = ds.field('date') >= min_date_pa\n",
    "            dataset = dataset.filter(filter_expr)\n",
    "\n",
    "        table = dataset.to_table(columns=columns)\n",
    "\n",
    "        # Log the schema for debugging\n",
    "        logger.info(f\"Schema for {s3_path} ({provider}):\")\n",
    "        logger.info(table.schema)\n",
    "\n",
    "        df = table.to_pandas()\n",
    "\n",
    "        partition_cols = ['ticker', 'date']\n",
    "        existing_cols = [col for col in partition_cols if col in df.columns]\n",
    "        other_cols = [col for col in df.columns if col not in partition_cols]\n",
    "        df = df[existing_cols + other_cols]\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data from {s3_path} ({provider}): {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# -------------------------------\n",
    "# Loading Functions\n",
    "# -------------------------------\n",
    "\n",
    "def load_data_by_ticker(\n",
    "    type_name,\n",
    "    providers=['wasabi', 'digitalocean'],\n",
    "    tickers=None,\n",
    "    start_date=None,\n",
    "    columns=None,\n",
    "    max_workers=4\n",
    "):\n",
    "    \"\"\"\n",
    "    Load data for specified tickers and/or dates from S3 storage providers.\n",
    "\n",
    "    Parameters:\n",
    "    - type_name (str): Type of data (e.g., 'applications', 'prediction_all', etc.)\n",
    "    - providers (list, optional): List of storage providers to load from ('wasabi', 'digitalocean')\n",
    "    - tickers (str or list, optional): Ticker symbol(s) to load data for\n",
    "    - start_date (str, optional): Minimum publishDate to filter data by (format 'YYYY-MM-DD') (only for date partitioning)\n",
    "    - columns (list, optional): List of columns to select\n",
    "    - max_workers (int, optional): Number of parallel threads\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: Concatenated DataFrame containing the loaded data\n",
    "    \"\"\"\n",
    "    date_tasks = []\n",
    "    ticker_tasks = []\n",
    "    results = []\n",
    "\n",
    "    # Normalize input parameters\n",
    "    if tickers and isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    if not tickers:\n",
    "        tickers = []\n",
    "    \n",
    "    # If both tickers and min_date are provided\n",
    "    if tickers and start_date:\n",
    "        try:\n",
    "            min_date_obj = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "            min_year = min_date_obj.year\n",
    "            logger.info(f\"Minimum date provided: {min_date_obj} (Year: {min_year})\")\n",
    "        except ValueError:\n",
    "            logger.error(f\"Invalid min_date format: {start_date}. Expected 'YYYY-MM-DD'.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        for provider in providers:\n",
    "            for ticker in tickers:\n",
    "                # Determine the range of years to load based on start_date\n",
    "                # Assuming data starts from 2011\n",
    "                start_year = min_year\n",
    "                current_year = datetime.datetime.now().year\n",
    "                for year in range(start_year, current_year + 1):\n",
    "                    s3_path = construct_s3_path(\n",
    "                        type_name, provider, partition_type=\"ticker\",\n",
    "                        ticker=ticker, year=year\n",
    "                    )\n",
    "                    ticker_tasks.append((s3_path, provider, columns, None))  # No additional filtering here\n",
    "\n",
    "    # If only min_date is provided\n",
    "    elif start_date and not tickers:\n",
    "        try:\n",
    "            min_date_obj = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "            logger.info(f\"Minimum date provided: {min_date_obj}\")\n",
    "        except ValueError:\n",
    "            logger.error(f\"Invalid start_date format: {start_date}. Expected 'YYYY-MM-DD'.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        for provider in providers:\n",
    "            # List all date-based partitions\n",
    "            date_partitions = list_date_partitions(provider, type_name)\n",
    "            for date_obj, partition_path in date_partitions:\n",
    "                if date_obj >= min_date_obj:\n",
    "                    date_tasks.append((partition_path, provider, columns, None))\n",
    "\n",
    "    # If only tickers are provided\n",
    "    elif tickers and not start_date:\n",
    "        for provider in providers:\n",
    "            for ticker in tickers:\n",
    "                # Assuming data starts from 2011\n",
    "                start_year = 2010 ## Change this to 2008 eventually\n",
    "                current_year = datetime.datetime.now().year\n",
    "                for year in range(start_year, current_year + 1):\n",
    "                    s3_path = construct_s3_path(\n",
    "                        type_name, provider, partition_type=\"ticker\",\n",
    "                        ticker=ticker, year=year\n",
    "                    )\n",
    "                    ticker_tasks.append((s3_path, provider, columns, None))\n",
    "\n",
    "    else:\n",
    "        logger.warning(\"No tickers or start_date provided. Please provide at least one.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Combine all tasks\n",
    "    all_tasks = ticker_tasks + date_tasks\n",
    "\n",
    "    if not all_tasks:\n",
    "        logger.warning(\"No tasks to process. Exiting.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def load_task(task):\n",
    "        s3_path, provider, columns, ticker_filter = task\n",
    "        df = load_parquet_from_s3(s3_path, provider, columns, start_date=start_date if ticker_filter is None else None)\n",
    "        if not df.empty and ticker_filter:\n",
    "            if 'ticker' in df.columns:\n",
    "                df = df[df['ticker'].isin(ticker_filter)]\n",
    "            else:\n",
    "                logger.warning(f\"'ticker' column not found in data from {s3_path} ({provider}). Skipping ticker filter.\")\n",
    "        return df\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(load_task, task): task for task in all_tasks}\n",
    "        for future in tqdm(as_completed(future_to_task), total=len(all_tasks), desc=\"Loading data\"):\n",
    "            df = future.result()\n",
    "            if not df.empty:\n",
    "                results.append(df)\n",
    "\n",
    "    if results:\n",
    "        final_df = pd.concat(results, ignore_index=True)\n",
    "        logger.info(f\"Successfully loaded data with {len(final_df)} records.\")\n",
    "    else:\n",
    "        final_df = pd.DataFrame()\n",
    "        logger.warning(\"No data found.\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# -------------------------------\n",
    "# Example Usage\n",
    "# -------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2568e2-745b-4baf-8d2c-5238e7d41ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "import pandas as pd\n",
    "\n",
    "sov.token_auth(token=\"visit https://sov.ai/profile for your token\")\n",
    "\n",
    "df = sov.data(\"patents/applications\", tickers=[\"GM\",\"MSFT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096ac519-859c-47b0-935d-a06d7b05d8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2e9c04-d7ae-438c-be07-ae0935f0e787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>applicationid</th>\n",
       "      <th>publicationid</th>\n",
       "      <th>orgname</th>\n",
       "      <th>subsidiary_name</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>ipc3</th>\n",
       "      <th>naics</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>description</th>\n",
       "      <th>claims</th>\n",
       "      <th>claimsnum</th>\n",
       "      <th>drawingsnum</th>\n",
       "      <th>filedate</th>\n",
       "      <th>apptype</th>\n",
       "      <th>kind</th>\n",
       "      <th>usseriescode</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GM</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>12496939</td>\n",
       "      <td>20110000195</td>\n",
       "      <td>GM GLOBAL TECHNOLOGY OPERATIONS, INC.</td>\n",
       "      <td>GM Global Technology Operations, Inc</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>F16</td>\n",
       "      <td>333612.000</td>\n",
       "      <td>REDUCED VOLUME ELECTRICALLY HEATED PARTICULATE...</td>\n",
       "      <td>A control system comprises an exhaust treatmen...</td>\n",
       "      <td>FIELD  The present disclosure relates to engin...</td>\n",
       "      <td>1 . An exhaust treatment system comprising: a ...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-07-02</td>\n",
       "      <td>utility</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>/tmp/2011_application_ipa110106/ipa110106.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GM</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>12496773</td>\n",
       "      <td>20110000194</td>\n",
       "      <td>GM GLOBAL TECHNOLOGY OPERATIONS, INC.</td>\n",
       "      <td>GM Global Technology Operations, Inc</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>F16</td>\n",
       "      <td>333612.000</td>\n",
       "      <td>SELECTIVE CATALYTIC REDUCTION SYSTEM USING ELE...</td>\n",
       "      <td>An exhaust system includes N heating elements ...</td>\n",
       "      <td>FIELD  The present disclosure relates to emiss...</td>\n",
       "      <td>1 . An exhaust system comprising: N heating el...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-07-02</td>\n",
       "      <td>utility</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>/tmp/2011_application_ipa110106/ipa110106.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>12497742</td>\n",
       "      <td>20110000421</td>\n",
       "      <td>GM GLOBAL TECHNOLOGY OPERATIONS, INC.</td>\n",
       "      <td>GM Global Technology Operations, Inc</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>F16</td>\n",
       "      <td>333612.000</td>\n",
       "      <td>METHOD AND APPARATUS TO ESTIMATE AUTOMOTIVE AL...</td>\n",
       "      <td>An embodiment contemplates a method for determ...</td>\n",
       "      <td>BACKGROUND OF INVENTION  An embodiment relates...</td>\n",
       "      <td>1 . A method for determining belt slip in a ve...</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-07-06</td>\n",
       "      <td>utility</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>/tmp/2011_application_ipa110106/ipa110106.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GM</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>12497000</td>\n",
       "      <td>20110000596</td>\n",
       "      <td>GM GLOBAL TECHNOLOGY OPERATIONS, INC.</td>\n",
       "      <td>GM Global Technology Operations, Inc</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>F16</td>\n",
       "      <td>333612.000</td>\n",
       "      <td>LOW NOISE RUN-FLAT TIRES</td>\n",
       "      <td>A tire includes a pair of sidewalls in spaced ...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION  The subject matte...</td>\n",
       "      <td>1 . A tire comprising: a pair of sidewalls in ...</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-07-02</td>\n",
       "      <td>utility</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>/tmp/2011_application_ipa110106/ipa110106.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GM</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>12830187</td>\n",
       "      <td>20110000729</td>\n",
       "      <td>GM GLOBAL TECHNOLOGY OPERATIONS, INC.</td>\n",
       "      <td>GM Global Technology Operations, Inc</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>US</td>\n",
       "      <td>F16</td>\n",
       "      <td>333612.000</td>\n",
       "      <td>FLOOR STRUCTURE FOR A MOTOR VEHICLE</td>\n",
       "      <td>A floor structure of a motor vehicle is provid...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION  This a...</td>\n",
       "      <td>1 . A floor structure for a motor vehicle, com...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>utility</td>\n",
       "      <td>A1</td>\n",
       "      <td>12</td>\n",
       "      <td>/tmp/2011_application_ipa110106/ipa110106.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date applicationid publicationid  \\\n",
       "0     GM 2011-01-06      12496939   20110000195   \n",
       "1     GM 2011-01-06      12496773   20110000194   \n",
       "2     GM 2011-01-06      12497742   20110000421   \n",
       "3     GM 2011-01-06      12497000   20110000596   \n",
       "4     GM 2011-01-06      12830187   20110000729   \n",
       "\n",
       "                                 orgname  \\\n",
       "0  GM GLOBAL TECHNOLOGY OPERATIONS, INC.   \n",
       "1  GM GLOBAL TECHNOLOGY OPERATIONS, INC.   \n",
       "2  GM GLOBAL TECHNOLOGY OPERATIONS, INC.   \n",
       "3  GM GLOBAL TECHNOLOGY OPERATIONS, INC.   \n",
       "4  GM GLOBAL TECHNOLOGY OPERATIONS, INC.   \n",
       "\n",
       "                        subsidiary_name  location country ipc3      naics  \\\n",
       "0  GM Global Technology Operations, Inc  Michigan      US  F16 333612.000   \n",
       "1  GM Global Technology Operations, Inc  Michigan      US  F16 333612.000   \n",
       "2  GM Global Technology Operations, Inc  Michigan      US  F16 333612.000   \n",
       "3  GM Global Technology Operations, Inc  Michigan      US  F16 333612.000   \n",
       "4  GM Global Technology Operations, Inc  Michigan      US  F16 333612.000   \n",
       "\n",
       "                                               title  \\\n",
       "0  REDUCED VOLUME ELECTRICALLY HEATED PARTICULATE...   \n",
       "1  SELECTIVE CATALYTIC REDUCTION SYSTEM USING ELE...   \n",
       "2  METHOD AND APPARATUS TO ESTIMATE AUTOMOTIVE AL...   \n",
       "3                           LOW NOISE RUN-FLAT TIRES   \n",
       "4                FLOOR STRUCTURE FOR A MOTOR VEHICLE   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A control system comprises an exhaust treatmen...   \n",
       "1  An exhaust system includes N heating elements ...   \n",
       "2  An embodiment contemplates a method for determ...   \n",
       "3  A tire includes a pair of sidewalls in spaced ...   \n",
       "4  A floor structure of a motor vehicle is provid...   \n",
       "\n",
       "                                         description  \\\n",
       "0  FIELD  The present disclosure relates to engin...   \n",
       "1  FIELD  The present disclosure relates to emiss...   \n",
       "2  BACKGROUND OF INVENTION  An embodiment relates...   \n",
       "3  BACKGROUND OF THE INVENTION  The subject matte...   \n",
       "4  CROSS-REFERENCE TO RELATED APPLICATION  This a...   \n",
       "\n",
       "                                              claims  claimsnum  drawingsnum  \\\n",
       "0  1 . An exhaust treatment system comprising: a ...         20            7   \n",
       "1  1 . An exhaust system comprising: N heating el...         18            5   \n",
       "2  1 . A method for determining belt slip in a ve...         20            5   \n",
       "3  1 . A tire comprising: a pair of sidewalls in ...         25            6   \n",
       "4  1 . A floor structure for a motor vehicle, com...         16            5   \n",
       "\n",
       "     filedate  apptype kind usseriescode  \\\n",
       "0  2009-07-02  utility   A1           12   \n",
       "1  2009-07-02  utility   A1           12   \n",
       "2  2009-07-06  utility   A1           12   \n",
       "3  2009-07-02  utility   A1           12   \n",
       "4  2010-07-02  utility   A1           12   \n",
       "\n",
       "                                        filename  \n",
       "0  /tmp/2011_application_ipa110106/ipa110106.xml  \n",
       "1  /tmp/2011_application_ipa110106/ipa110106.xml  \n",
       "2  /tmp/2011_application_ipa110106/ipa110106.xml  \n",
       "3  /tmp/2011_application_ipa110106/ipa110106.xml  \n",
       "4  /tmp/2011_application_ipa110106/ipa110106.xml  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9941bf18-2ec1-486b-9741-7919d920d732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14631, 22)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f5614b-fbea-4206-963b-3b590777dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 49.00it/s]\n"
     ]
    }
   ],
   "source": [
    "tickers_to_load = [\"AAPL\", \"MSFT\"]\n",
    "type_of_data = \"applications\"\n",
    "selected_columns = [\n",
    "    \"applicationid\", \"ticker\", \"date\"\n",
    "]\n",
    "start_date = \"2010-10-24\"\n",
    "\n",
    "logger.info(\"Starting data load with both tickers and start_date.\")\n",
    "loaded_df_both = load_data_by_ticker(\n",
    "    type_name=type_of_data,\n",
    "    providers=['digitalocean'],\n",
    "    tickers=tickers_to_load,\n",
    "    start_date=start_date,\n",
    "    columns=selected_columns,\n",
    "    max_workers=8  # Adjust based on your system's capabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a3cb1a-d402-4a48-a4db-a596e415c95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>applicationid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>12504392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-01-27</td>\n",
       "      <td>12692433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-01-27</td>\n",
       "      <td>12509413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-02-03</td>\n",
       "      <td>12902094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>12535974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2011-11-03</td>\n",
       "      <td>13179098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2011-11-10</td>\n",
       "      <td>13187206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2011-11-10</td>\n",
       "      <td>13185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>13190538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2011-12-29</td>\n",
       "      <td>13228879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker       date applicationid\n",
       "0     AAPL 2011-01-20      12504392\n",
       "1     AAPL 2011-01-27      12692433\n",
       "2     AAPL 2011-01-27      12509413\n",
       "3     AAPL 2011-02-03      12902094\n",
       "4     AAPL 2011-02-10      12535974\n",
       "..     ...        ...           ...\n",
       "463   MSFT 2011-11-03      13179098\n",
       "464   MSFT 2011-11-10      13187206\n",
       "465   MSFT 2011-11-10      13185000\n",
       "466   MSFT 2011-11-17      13190538\n",
       "467   MSFT 2011-12-29      13228879\n",
       "\n",
       "[468 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423ae6fc-8030-4768-963c-b9c11484575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del loaded_df_both"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
